import streamlit as st
import duckdb
import polars as pl
import io
import time
import json
from pathlib import Path

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DATA_DIR = Path("./auto_parts_data")
DATA_DIR.mkdir(exist_ok=True)
DB_PATH = DATA_DIR / "catalog.duckdb"

class AutoPartsCatalog:
    def __init__(self):
        self.conn = duckdb.connect(str(DB_PATH))
        self._setup_database()
        self._create_indexes()

    def _setup_database(self):
        # –¢–∞–±–ª–∏—Ü—ã
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS oe_data (
                oe_number_norm VARCHAR PRIMARY KEY,
                oe_number VARCHAR,
                name VARCHAR,
                applicability VARCHAR,
                category VARCHAR
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS parts_data (
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                artikul VARCHAR,
                brand VARCHAR,
                multiplicity INTEGER,
                barcode VARCHAR,
                length DOUBLE,
                width DOUBLE,
                height DOUBLE,
                weight DOUBLE,
                image_url VARCHAR,
                dimensions_str VARCHAR,
                description VARCHAR,
                price_with_markup DOUBLE,
                category VARCHAR,
                PRIMARY KEY (artikul_norm, brand_norm)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS cross_references (
                oe_number_norm VARCHAR,
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                PRIMARY KEY (oe_number_norm, artikul_norm, brand_norm)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS recommended_prices (
                artikul_norm VARCHAR PRIMARY KEY,
                price DOUBLE
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS price_list (
                artikul VARCHAR,
                brand VARCHAR,
                quantity INTEGER,
                price DOUBLE,
                PRIMARY KEY (artikul, brand)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS markup_settings (
                id INTEGER PRIMARY KEY,
                total_markup DOUBLE,
                brand_markup JSON
            )
        """)
        if not self.conn.execute("SELECT 1 FROM markup_settings").fetchone():
            self.conn.execute("INSERT INTO markup_settings (id, total_markup, brand_markup) VALUES (1, 0, '{}')")
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS categories (
                name VARCHAR PRIMARY KEY,
                description VARCHAR
            )
        """)

    def _create_indexes(self):
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_oe ON oe_data(oe_number_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_parts ON parts_data(artikul_norm, brand_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_cross ON cross_references(oe_number_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_cross_art ON cross_references(artikul_norm, brand_norm)")

    # --- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ ---
    def get_categories(self):
        return self.conn.execute("SELECT name, description FROM categories").fetchdf()

    def add_category(self, name, description=''):
        try:
            self.conn.execute("INSERT INTO categories (name, description) VALUES (?, ?)", [name, description])
        except Exception:
            pass

    def delete_category(self, name):
        self.conn.execute("DELETE FROM categories WHERE name=?", [name])

    def update_category_name(self, old_name, new_name):
        self.conn.execute("UPDATE categories SET name=? WHERE name=?", [new_name, old_name])

    def load_categories(self, file_bytes):
        try:
            df = pl.read_excel(io.BytesIO(file_bytes))
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
            return
        if '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' not in df.columns or '–∫–∞—Ç–µ–≥–æ—Ä–∏—è' not in df.columns:
            st.error("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' –∏ '–∫–∞—Ç–µ–≥–æ—Ä–∏—è'")
            return
        df = df.select([pl.col('–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'), pl.col('–∫–∞—Ç–µ–≥–æ—Ä–∏—è')])
        self.conn.execute("DELETE FROM categories")
        for row in df.iter_rows():
            self.add_category(row[0], row[1])

    def show_categories(self):
        df = self.get_categories()
        st.subheader("–¢–µ–∫—É—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
        edited_df = st.experimental_data_editor(df, use_container_width=True)
        if st.button("–û–±–Ω–æ–≤–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"):
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –∏ —É–¥–∞–ª–µ–Ω–∏–µ
            original_names = df['name'].tolist()
            updated_names = edited_df['name'].tolist()
            for old_name, new_name in zip(original_names, edited_df['name']):
                if old_name != new_name:
                    self.update_category_name(old_name, new_name)
            # –£–¥–∞–ª–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö
            for name in original_names:
                if name not in edited_df['name'].tolist():
                    self.delete_category(name)
            st.success("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ ---
    def read_and_prepare_file(self, filepath, key):
        try:
            df = pl.read_excel(filepath)
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
            if key == 'oe':
                df = df.rename({"‚Ññ OE": "oe_number", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ": "name", "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å": "applicability", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": "category"})
                df['oe_number_norm'] = df['oe_number'].str.strip().str.upper()
            elif key == 'cross':
                df = df.rename({"OE": "oe_number", "–ê—Ä—Ç–∏–∫—É–ª": "artikul", "–ë—Ä–µ–Ω–¥": "brand"})
                df['oe_number_norm'] = df['oe_number'].str.strip().str.upper()
                df['artikul_norm'] = df['artikul'].str.strip().str.upper()
            elif key == 'barcode':
                df = df.rename({"–ê—Ä—Ç–∏–∫—É–ª": "artikul", "–ë—Ä–µ–Ω–¥": "brand", "–®—Ç—Ä–∏—Ö–∫–æ–¥": "barcode"})
            elif key == 'dimensions':
                df = df.rename({"–ê—Ä—Ç–∏–∫—É–ª": "artikul", "–ë—Ä–µ–Ω–¥": "brand", "–î–ª–∏–Ω–∞": "length", "–®–∏—Ä–∏–Ω–∞": "width", "–í—ã—Å–æ—Ç–∞": "height", "–í–µ—Å": "weight"})
            elif key == 'images':
                df = df.rename({"–ê—Ä—Ç–∏–∫—É–ª": "artikul", "–ë—Ä–µ–Ω–¥": "brand", "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ": "image_url"})
            elif key == 'categories':
                # —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
                pass
            return df
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filepath}: {e}")
            return None

    def process_and_load(self, dataframes):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É
        if 'oe' in dataframes:
            df_oe = dataframes['oe']
            for row in df_oe.iter_rows():
                self.conn.execute("""
                    INSERT OR REPLACE INTO oe_data (oe_number_norm, oe_number, name, applicability, category)
                    VALUES (?, ?, ?, ?, ?)
                """, [row['oe_number_norm'], row['oe_number'], row['name'], row.get('applicability', ''), row.get('category', '')])
        if 'cross' in dataframes:
            df_cross = dataframes['cross']
            for row in df_cross.iter_rows():
                self.conn.execute("""
                    INSERT OR REPLACE INTO cross_references (oe_number_norm, artikul_norm, brand_norm)
                    VALUES (?, ?, ?)
                """, [row['oe_number'].strip().upper(), row['artikul'].strip().upper(), row['brand'].strip().upper()])
        if 'barcode' in dataframes:
            # –æ–±—Ä–∞–±–æ—Ç–∫–∞ —à—Ç—Ä–∏—Ö–∫–æ–¥–æ–≤
            pass
        if 'dimensions' in dataframes:
            df_dim = dataframes['dimensions']
            for row in df_dim.iter_rows():
                self.conn.execute("""
                    UPDATE OR INSERT INTO parts_data (artikul_norm, brand_norm, length, width, height, weight)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, [row['artikul'].strip().upper(), row['brand'].strip().upper(), row['length'], row['width'], row['height'], row['weight']])
        # –¥–æ–±–∞–≤—å—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

    def load_recommended_prices(self, file_bytes):
        try:
            df = pl.read_excel(io.BytesIO(file_bytes))
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return
        if '–ê—Ä—Ç–∏–∫—É–ª' not in df.columns or '–¶–µ–Ω–∞' not in df.columns:
            st.error("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å '–ê—Ä—Ç–∏–∫—É–ª' –∏ '–¶–µ–Ω–∞'")
            return
        for row in df.iter_rows():
            artikul = row['–ê—Ä—Ç–∏–∫—É–ª'].strip().upper()
            price = row['–¶–µ–Ω–∞']
            self.conn.execute("""
                INSERT OR REPLACE INTO recommended_prices (artikul_norm, price)
                VALUES (?, ?)
            """, [artikul, price])
        st.success("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ü–µ–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

    def load_price_list(self, file_bytes):
        try:
            df = pl.read_excel(io.BytesIO(file_bytes))
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞: {e}")
            return
        if not {'–ê—Ä—Ç–∏–∫—É–ª', '–ë—Ä–µ–Ω–¥', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–¶–µ–Ω–∞'}.issubset(df.columns):
            st.error("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å '–ê—Ä—Ç–∏–∫—É–ª', '–ë—Ä–µ–Ω–¥', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–¶–µ–Ω–∞'")
            return
        for row in df.iter_rows():
            artikul = row['–ê—Ä—Ç–∏–∫—É–ª'].strip().upper()
            brand = row['–ë—Ä–µ–Ω–¥'].strip()
            quantity = row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
            price = row['–¶–µ–Ω–∞']
            self.conn.execute("""
                INSERT OR REPLACE INTO price_list (artikul, brand, quantity, price)
                VALUES (?, ?, ?, ?)
            """, [artikul, brand, quantity, price])
        st.success("–ü—Ä–∞–π—Å-–ª–∏—Å—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")

    # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–æ–∫ ---
    def get_markups(self):
        row = self.conn.execute("SELECT total_markup, brand_markup FROM markup_settings WHERE id=1").fetchone()
        if row:
            total_markup, brand_markup_json = row
            try:
                brand_markup = json.loads(brand_markup_json) if brand_markup_json else {}
            except:
                brand_markup = {}
            return total_markup, brand_markup
        return 0, {}

    def set_markups(self, total_markup, brand_markup):
        self.conn.execute("""
            UPDATE markup_settings SET total_markup=?, brand_markup=?
            WHERE id=1
        """, [total_markup, json.dumps(brand_markup)])
        st.success("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")

    def apply_markup(self, price, total_markup, brand_markup_dict, brand):
        markup = total_markup
        if brand and brand in brand_markup_dict:
            markup += brand_markup_dict[brand]
        return round(price * (1 + markup / 100), 2)

    # --- –≠–∫—Å–ø–æ—Ä—Ç ---
    def show_export_interface(self):
        st.subheader("–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        all_cols = [
            'artikul', 'brand', 'category', 'length', 'width', 'height', 'weight',
            'image_url', 'description', 'oe_list', 'price_with_markup'
        ]
        selected_cols = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–≤ –∂–µ–ª–∞–µ–º–æ–º –ø–æ—Ä—è–¥–∫–µ)", all_cols, default=all_cols)
        exclude_input = st.text_input("–ò—Å–∫–ª—é—á–∏—Ç—å –ø–æ–∑–∏—Ü–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é (—á–µ—Ä–µ–∑ |)", "")

        categories = self.get_categories()['name'].tolist()
        categories.insert(0, '–í—Å–µ')
        category_filter = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º", categories, default=['–í—Å–µ'])
        if '–í—Å–µ' in category_filter:
            category_filter = None
        elif not category_filter:
            category_filter = None
        else:
            category_filter = category_filter

        total_markup_value = st.number_input("–û–±—â–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ (%)", value=0.0, step=0.1)
        brand_markup_df = self.conn.execute("SELECT brand, COUNT(*) as cnt FROM parts_data GROUP BY brand").fetchdf()
        brand_markup_dict = {}
        st.write("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–æ–∫ –ø–æ –±—Ä–µ–Ω–¥–∞–º:")
        for index, row in brand_markup_df.iterrows():
            brand = row['brand']
            default_markup = 0.0
            markup_value = st.number_input(f"{brand}", value=default_markup, step=0.1, key=f"markup_{brand}")
            brand_markup_dict[brand] = markup_value

        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–∫–∏"):
            self.set_markups(total_markup_value, brand_markup_dict)

        if st.button("–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ"):
            df = self.export_data(
                columns=selected_cols,
                exclude_terms=exclude_input,
                category_filter=None if '–í—Å–µ' in category_filter else category_filter
            )
            if df is not None:
                total_markup, brand_markup = self.get_markups()
                if 'price_with_markup' in df.columns:
                    df = df.with_columns(
                        pl.col('price_with_markup').apply(
                            lambda p, br=pl.col('brand'): self.apply_markup(p, total_markup, brand_markup, br[0])
                        ).alias('price_with_markup')
                    )
                buffer = io.BytesIO()
                df.write_excel(buffer)
                buffer.seek(0)
                filename = f"export_{int(time.time())}.xlsx"
                st.download_button("–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª", data=buffer, file_name=filename, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# --- –ì–ª–∞–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ---
def main():
    st.set_page_config(page_title="AutoParts Catalog", layout="wide")
    st.title("üöó AutoParts Catalog ‚Äî –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç")
    catalog = AutoPartsCatalog()

    menu = st.sidebar.radio("–ú–µ–Ω—é", ["–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", "–ù–∞—Å—Ç—Ä–æ–π–∫–∏", "–≠–∫—Å–ø–æ—Ä—Ç", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ü–µ–Ω", "–ü—Ä–∞–π—Å-–ª–∏—Å—Ç"])

    if menu == "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö":
        st.subheader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        col1, col2 = st.columns(2)
        with col1:
            file_oe = st.file_uploader("–û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OE)", type=['xlsx', 'xls'])
            file_cross = st.file_uploader("–ö—Ä–æ—Å—Å—ã (OE ‚Üí –ê—Ä—Ç–∏–∫—É–ª)", type=['xlsx', 'xls'])
            file_barcode = st.file_uploader("–®—Ç—Ä–∏—Ö-–∫–æ–¥—ã", type=['xlsx', 'xls'])
        with col2:
            file_dim = st.file_uploader("–í–µ—Å–æ–≥–∞–±–∞—Ä–∏—Ç—ã", type=['xlsx', 'xls'])
            file_img = st.file_uploader("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", type=['xlsx', 'xls'])
            file_category = st.file_uploader("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ, –∫–∞—Ç–µ–≥–æ—Ä–∏—è)", type=['xlsx', 'xls'])

        files_map = {
            'oe': file_oe,
            'cross': file_cross,
            'barcode': file_barcode,
            'dimensions': file_dim,
            'images': file_img,
            'categories': file_category
        }

        if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª—ã"):
            dataframes = {}
            for key, uploaded in files_map.items():
                if uploaded:
                    filename = f"{key}_{int(time.time())}_{uploaded.name}"
                    path = DATA_DIR / filename
                    with open(path, "wb") as f:
                        f.write(uploaded.read())
                    df = catalog.read_and_prepare_file(str(path), key)
                    dataframes[key] = df
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            if 'categories' in files_map and files_map['categories']:
                catalog.load_categories(files_map['categories'].read())

            if dataframes:
                catalog.process_and_load(dataframes)
                st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            else:
                st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")

    elif menu == "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏":
        catalog.show_categories()

    elif menu == "–ù–∞—Å—Ç—Ä–æ–π–∫–∏":
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–æ–∫")
        total_markup, brand_markup = catalog.get_markups()
        new_total_markup = st.number_input("–û–±—â–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ (%)", value=total_markup, step=0.1)
        brand_df = catalog.conn.execute("SELECT brand FROM parts_data GROUP BY brand").fetchdf()
        brand_markup_dict = {}
        st.write("–ù–∞—Ü–µ–Ω–∫–∏ –ø–æ –±—Ä–µ–Ω–¥–∞–º:")
        for index, row in brand_df.iterrows():
            brand = row['brand']
            default_markup = brand_markup.get(brand, 0)
            markup_value = st.number_input(f"{brand}", value=default_markup, step=0.1, key=f"markup_{brand}")
            brand_markup_dict[brand] = markup_value
        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–∫–∏"):
            catalog.set_markups(new_total_markup, brand_markup_dict)

    elif menu == "–≠–∫—Å–ø–æ—Ä—Ç":
        catalog.show_export_interface()

    elif menu == "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
        stats = catalog.get_statistics()
        st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        st.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—á–∞—Å—Ç–µ–π: {stats['total_parts']}")
        st.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {stats['total_categories']}")

    elif menu == "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ü–µ–Ω":
        uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ —Ü–µ–Ω–∞–º", type=['xlsx', 'xls'])
        if uploaded:
            catalog.load_recommended_prices(uploaded.read())

    elif menu == "–ü—Ä–∞–π—Å-–ª–∏—Å—Ç":
        uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç", type=['xlsx', 'xls'])
        if uploaded:
            catalog.load_price_list(uploaded.read())

if __name__ == "__main__":
    main()
