import polars as pl
import duckdb
import streamlit as st
import os
import time
import io
import zipfile
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')

EXCEL_ROW_LIMIT = 1_000_000

class AutoPartsCatalog:
    def __init__(self):
        self.data_dir = Path("./auto_parts_data")
        self.data_dir.mkdir(exist_ok=True)
        self.db_path = self.data_dir / "catalog.duckdb"
        self.conn = duckdb.connect(str(self.db_path))
        self.setup_database()
        self.load_recommended_prices()

        self.categories = {}  # –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –∫–ª—é—á—É
        self.brand_markups: dict = {}
        self.global_markup: float = 0.0

    def setup_database(self):
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS oe_data (
                oe_number_norm VARCHAR PRIMARY KEY,
                oe_number VARCHAR,
                name VARCHAR,
                applicability VARCHAR,
                category VARCHAR
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS parts_data (
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                artikul VARCHAR,
                brand VARCHAR,
                category VARCHAR,
                multiplicity INTEGER,
                barcode VARCHAR,
                image_url VARCHAR,
                dimensions_str VARCHAR,
                description VARCHAR,
                recommended_price DOUBLE,
                price_with_markup DOUBLE,
                PRIMARY KEY (artikul_norm, brand_norm)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS cross_references (
                oe_number_norm VARCHAR,
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                PRIMARY KEY (oe_number_norm, artikul_norm, brand_norm)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS supplier_prices (
                artikul VARCHAR,
                quantity INTEGER,
                brand VARCHAR,
                supplier_price DOUBLE,
                PRIMARY KEY (artikul, brand)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS prices (
                artikul VARCHAR PRIMARY KEY,
                recommended_price DOUBLE,
                brand VARCHAR
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS categories (
                key VARCHAR PRIMARY KEY,
                name VARCHAR
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS markup_settings (
                id INTEGER PRIMARY KEY,
                global_markup DOUBLE
            )
        """)
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.conn.execute("INSERT OR IGNORE INTO markup_settings (id, global_markup) VALUES (1, 0.0)")

    def load_recommended_prices(self):
        filepath = self.data_dir / "recommended_prices.xlsx"
        if filepath.exists():
            df = pl.read_excel(str(filepath))
            for row in df.rows():
                artikul, price, brand = row
                self.conn.execute("""
                    INSERT OR REPLACE INTO prices (artikul, recommended_price, brand)
                    VALUES (?, ?, ?)
                """, [artikul, price, brand])
            st.info("–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–Ω—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
        else:
            pass

    def save_recommended_prices(self, df: pl.DataFrame):
        for row in df.rows():
            artikul, price, brand = row
            self.conn.execute("""
                INSERT OR REPLACE INTO prices (artikul, recommended_price, brand)
                VALUES (?, ?, ?)
            """, [artikul, price, brand])
        st.success("–¶–µ–Ω—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")

    def get_global_markup(self):
        res = self.conn.execute("SELECT global_markup FROM markup_settings WHERE id=1").fetchone()
        return res[0] if res else 0.0

    def set_global_markup(self, percent: float):
        self.conn.execute("UPDATE markup_settings SET global_markup=?", [percent])
        self.global_markup = percent

    def get_brand_markup(self, brand: str):
        return self.brand_markups.get(brand, 0.0)

    def set_brand_markup(self, brand: str, percent: float):
        self.brand_markups[brand] = percent

    def create_indexes(self):
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_oe ON oe_data(oe_number_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_parts ON parts_data(artikul_norm, brand_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_cross ON cross_references(oe_number_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_prices ON prices(artikul)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_categories ON categories(key)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_markup ON markup_settings(id)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_supplier ON supplier_prices(artikul, brand)")

    @staticmethod
    def normalize_key(series):
        return (
            series
            .fill_null("")
            .cast(pl.Utf8)
            .str.replace_all("'", "")
            .str.replace_all(r"[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\-\s]", "")
            .str.replace_all(r"\s+", " ")
            .str.strip_chars()
            .str.to_lowercase()
        )

    @staticmethod
    def clean_values(series):
        return (
            series
            .fill_null("")
            .cast(pl.Utf8)
            .str.replace_all("'", "")
            .str.replace_all(r"[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\-\s]", "")
            .str.replace_all(r"\s+", " ")
            .str.strip_chars()
        )

    def detect_columns(self, actual_cols, expected_cols):
        mapping = {}
        col_variants = {
            'oe_number': ['oe –Ω–æ–º–µ—Ä', 'oe', '–æe', '–Ω–æ–º–µ—Ä', 'code', 'OE'],
            'artikul': ['–∞—Ä—Ç–∏–∫—É–ª', 'article', 'sku'],
            'brand': ['–±—Ä–µ–Ω–¥', 'brand', '–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å', 'manufacturer'],
            'name': ['–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–Ω–∞–∑–≤–∞–Ω–∏–µ', 'name', '–æ–ø–∏—Å–∞–Ω–∏–µ', 'description'],
            'applicability': ['–ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å', '–∞–≤—Ç–æ–º–æ–±–∏–ª—å', 'vehicle', 'applicability'],
            'barcode': ['—à—Ç—Ä–∏—Ö-–∫–æ–¥', 'barcode', '—à—Ç—Ä–∏—Ö–∫–æ–¥', 'ean', 'eac13'],
            'multiplicity': ['–∫—Ä–∞—Ç–Ω–æ—Å—Ç—å —à—Ç', '–∫—Ä–∞—Ç–Ω–æ—Å—Ç—å', 'multiplicity'],
            'length': ['–¥–ª–∏–Ω–∞ (—Å–º)', '–¥–ª–∏–Ω–∞', 'length', '–¥–ª–∏–Ω–Ω–∞'],
            'width': ['—à–∏—Ä–∏–Ω–∞ (—Å–º)', '—à–∏—Ä–∏–Ω–∞', 'width'],
            'height': ['–≤—ã—Å–æ—Ç–∞ (—Å–º)', '–≤—ã—Å–æ—Ç–∞', 'height'],
            'weight': ['–≤–µ—Å (–∫–≥)', '–≤–µ—Å, –∫–≥', '–≤–µ—Å', 'weight'],
            'image_url': ['—Å—Å—ã–ª–∫–∞', 'url', '–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', 'image', '–∫–∞—Ä—Ç–∏–Ω–∫–∞'],
            'dimensions_str': ['–≤–µ—Å–æ–≥–∞–±–∞—Ä–∏—Ç—ã', '—Ä–∞–∑–º–µ—Ä—ã', 'dimensions', 'size']
        }
        actual_lower = {col.lower(): col for col in actual_cols}
        for key, variants in col_variants.items():
            for variant in variants:
                for actual_l, original_name in actual_lower.items():
                    if variant in actual_l:
                        mapping[original_name] = key
                        break
        return mapping

    def read_and_prepare_file(self, file_path: str, file_type: str):
        try:
            if not os.path.exists(file_path):
                return pl.DataFrame()
            df = pl.read_excel(file_path, engine='calamine')
            if df.is_empty():
                return pl.DataFrame()
            expected = {
                'oe': ['oe_number', 'artikul', 'brand', 'name', 'applicability'],
                'barcode': ['barcode', 'artikul', 'brand', 'multiplicity'],
                'dimensions': ['artikul', 'brand', 'length', 'width', 'height', 'weight', 'dimensions_str'],
                'images': ['artikul', 'brand', 'image_url'],
                'cross': ['oe_number', 'artikul', 'brand']
            }
            expected_cols = expected.get(file_type, [])
            col_map = self.detect_columns(df.columns, expected_cols)
            if not col_map:
                return pl.DataFrame()
            df = df.rename(col_map)
            # –û—á–∏—Å—Ç–∫–∞
            if 'artikul' in df.columns:
                df = df.with_columns(artikul=self.clean_values(pl.col('artikul')))
            if 'brand' in df.columns:
                df = df.with_columns(brand=self.clean_values(pl.col('brand')))
            if 'oe_number' in df.columns:
                df = df.with_columns(oe_number=self.clean_values(pl.col('oe_number')))
            # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            key_cols = [c for c in ['oe_number', 'artikul', 'brand'] if c in df.columns]
            if key_cols:
                df = df.unique(subset=key_cols, keep='first')
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª—é—á–µ–π
            if 'artikul' in df.columns:
                df = df.with_columns(artikul_norm=self.normalize_key(pl.col('artikul')))
            if 'brand' in df.columns:
                df = df.with_columns(brand_norm=self.normalize_key(pl.col('brand')))
            if 'oe_number' in df.columns:
                df = df.with_columns(oe_number_norm=self.normalize_key(pl.col('oe_number')))
            return df
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return pl.DataFrame()

    def upsert(self, table: str, df: pl.DataFrame, pk: list):
        if df.is_empty():
            return
        df = df.unique(keep='first')
        cols = df.columns
        pk_str = ", ".join([f'"{c}"' for c in pk])
        temp_name = f"temp_{table}_{int(time.time())}"
        self.conn.register(temp_name, df.to_arrow())
        set_clause = ", ".join([f'"{col}"=excluded."{col}"' for col in cols if col not in pk])
        sql = f"""
        INSERT INTO {table} ({', '.join(['"'+c+'"' for c in cols])})
        SELECT * FROM {temp_name}
        ON CONFLICT ({pk_str}) DO UPDATE SET {set_clause}
        """
        self.conn.execute(sql)
        self.conn.unregister(temp_name)

    def process_and_load(self, dfs: dict):
        st.info("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ OE
        if 'oe' in dfs:
            df_oe = dfs['oe'].filter(pl.col('oe_number_norm') != "")
            oe_df = df_oe.select(['oe_number_norm', 'oe_number', 'name', 'applicability']).unique(subset=['oe_number_norm'])
            if 'name' in oe_df.columns:
                oe_df = oe_df.with_columns(self.determine_category_vectorized(pl.col('name')))
            else:
                oe_df = oe_df.with_columns(category=pl.lit('–†–∞–∑–Ω–æ–µ'))
            self.upsert('oe_data', oe_df, ['oe_number_norm'])
            cross_df = df_oe.select(['oe_number_norm', 'artikul_norm', 'brand_norm']).unique()
            self.upsert('cross_references', cross_df, ['oe_number_norm', 'artikul_norm', 'brand_norm'])

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ cross
        if 'cross' in dfs:
            df_cross = dfs['cross'].filter((pl.col('oe_number_norm') != "") & (pl.col('artikul_norm') != ""))
            self.upsert('cross_references', df_cross, ['oe_number_norm', 'artikul_norm', 'brand_norm'])

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ parts
        all_parts = None
        for key in ['oe', 'barcode', 'images', 'dimensions']:
            df = dfs.get(key)
            if df is None or df.is_empty():
                continue
            if 'artikul_norm' in df.columns:
                temp = df.select(['artikul', 'artikul_norm', 'brand', 'brand_norm', 'category'])
                if all_parts is None:
                    all_parts = temp
                else:
                    all_parts = all_parts.join(temp, on=['artikul_norm', 'brand_norm'], how='left', coalesce=True)
        if all_parts is None:
            all_parts = pl.DataFrame()

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ü–µ–Ω
        prices_df = self.conn.execute("SELECT artikul, recommended_price, brand FROM prices").pl()
        if not all_parts.is_empty():
            all_parts = all_parts.join(prices_df, on='artikul', how='left')
            # –†–∞–∑–º–µ—Ä—ã
            for c in ['length', 'width', 'height']:
                if c not in all_parts.columns:
                    all_parts = all_parts.with_columns(pl.lit(None).cast(pl.Float64).alias(c))
            if 'dimensions_str' not in all_parts.columns:
                all_parts = all_parts.with_columns(dimensions_str=pl.lit(''))
            # –û–ø–∏—Å–∞–Ω–∏–µ
            if 'artikul' not in all_parts.columns:
                all_parts = all_parts.with_columns(artikul=pl.lit(''))
            if 'brand' not in all_parts.columns:
                all_parts = all_parts.with_columns(brand=pl.lit(''))
            # –†–∞—Å—á–µ—Ç —Ü–µ–Ω—ã —Å –Ω–∞—Ü–µ–Ω–∫–æ–π
            def compute_price(row):
                base_price = row['recommended_price']
                if base_price is None or base_price == 0:
                    return None
                markup_percent = self.get_global_markup()
                brand_markup = self.get_brand_markup(row['brand']) if row['brand'] in self.brand_markups else 0.0
                total_markup = markup_percent + brand_markup
                return base_price * (1 + total_markup / 100)

            all_parts = all_parts.with_columns(
                pl.struct([pl.col('brand'), pl.col('recommended_price')])
                .apply(compute_price)
                .alias('price_with_markup')
            )

            # –§–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            all_parts = all_parts.select([
                'artikul_norm', 'brand_norm', 'artikul', 'brand', 'category', 'multiplicity', 'barcode',
                'length', 'width', 'height', 'weight', 'image_url', 'dimensions_str', 'description', 'price_with_markup'
            ])

            self.upsert('parts_data', all_parts, ['artikul_norm', 'brand_norm'])

        # –†–∞–±–æ—Ç–∞ —Å –ø—Ä–∞–π—Å–∞–º–∏ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤
        self.handle_supplier_prices()

        self.create_indexes()
        st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    def handle_supplier_prices(self):
        # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å —Ñ–∞–π–ª —Å –ø—Ä–∞–π—Å–∞–º–∏ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ (–∞—Ä—Ç–∏–∫—É–ª, –∫–æ–ª-–≤–æ, –±—Ä–µ–Ω–¥, —Ü–µ–Ω–∞)
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –µ–≥–æ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ –±–∞–∑—ã.
        # –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Å–æ–∑–¥–∞–¥–∏–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –¥–æ–±–∞–≤–∏–º —Å—é–¥–∞ –∫–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞.
        # –ü–æ–∫–∞ —á—Ç–æ –∑–∞–≥–ª—É—à–∫–∞:
        # –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞:
        uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∞–π—Å—ã –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ (Excel)", type=['xlsx','xls'])
        if uploaded:
            df_sup = pl.read_excel(uploaded)
            # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: –∞—Ä—Ç–∏–∫—É–ª, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –±—Ä–µ–Ω–¥, —Ü–µ–Ω–∞
            for row in df_sup.rows():
                artikul, quantity, brand, price = row
                self.conn.execute("""
                    INSERT OR REPLACE INTO supplier_prices (artikul, quantity, brand, supplier_price)
                    VALUES (?, ?, ?, ?)
                """, [artikul, quantity, brand, price])
            st.success("–ü—Ä–∞–π—Å—ã –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
        # –ú–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–≤—è–∑–∞—Ç—å —Å –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏ –≤ —á–∞—Å—Ç–∏ –∏–ª–∏ —Ç–∞–±–ª–∏—Ü–µ —Ü–µ–Ω.

    def get_total_parts(self):
        return self.conn.execute("SELECT COUNT(*) FROM parts_data").fetchone()[0]

    def get_statistics(self):
        total_parts = self.get_total_parts()
        total_oe = self.conn.execute("SELECT COUNT(*) FROM oe_data").fetchone()[0]
        total_brands = self.conn.execute("SELECT COUNT(DISTINCT brand) FROM parts_data").fetchone()[0]
        top_brands = self.conn.execute("SELECT brand, COUNT(*) as cnt FROM parts_data GROUP BY brand ORDER BY cnt DESC LIMIT 10").fetchdf()
        categories = self.conn.execute("SELECT category, COUNT(*) as cnt FROM oe_data WHERE category IS NOT NULL GROUP BY category ORDER BY cnt DESC").fetchdf()
        return {
            'total_parts': total_parts,
            'total_oe': total_oe,
            'total_brands': total_brands,
            'top_brands': top_brands,
            'categories': categories
        }

    def build_export_query(self, selected_cols=None, exclude_terms=None, filters=None):
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ SQL –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        exclude_where = ""
        if exclude_terms:
            clauses = []
            for term in exclude_terms:
                clauses.append(f"r.\"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\" NOT LIKE '%{term}%'")
            if clauses:
                exclude_where = " AND ".join(clauses)
            if exclude_where:
                exclude_where = "WHERE " + exclude_where

        filter_clauses = []
        if filters:
            if 'brand' in filters:
                brands = filters['brand']
                brand_list = ", ".join([f"'{b}'" for b in brands])
                filter_clauses.append(f"p.brand IN ({brand_list})")
            if 'category' in filters:
                cats = filters['category']
                cat_list = ", ".join([f"'{c}'" for c in cats])
                filter_clauses.append(f"p.category IN ({cat_list})")
            if 'artikul' in filters:
                arts = filters['artikul']
                arts_list = ", ".join([f"'{a}'" for a in arts])
                filter_clauses.append(f"p.artikul IN ({arts_list})")
            if 'oe' in filters:
                o_list = ", ".join([f"'{o}'" for o in filters['oe']])
                # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ —Å–≤—è–∑–∫–∞ —Å oe_data
                filter_clauses.append(f"pd.oe_list LIKE ANY (ARRAY[{o_list}])")
        filter_where = ""
        if filter_clauses:
            filter_where = " AND ".join(filter_clauses)
            filter_where = "WHERE " + filter_where

        columns_map = [
            ("–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", 'p.artikul AS "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞"'),
            ("–ë—Ä–µ–Ω–¥", 'p.brand AS "–ë—Ä–µ–Ω–¥"'),
            ("–ö–∞—Ç–µ–≥–æ—Ä–∏—è", 'p.category AS "–ö–∞—Ç–µ–≥–æ—Ä–∏—è"'),
            ("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", 'COALESCE(p.description, "") AS "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ"'),
            ("–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", 'COALESCE(pd.representative_applicability, "") AS "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å"'),
            ("–û–ø–∏—Å–∞–Ω–∏–µ", 'CONCAT(COALESCE(p.description, ""), dt.text) AS "–û–ø–∏—Å–∞–Ω–∏–µ"'),
            ("–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", 'p.multiplicity AS "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å"'),
            ("–î–ª–∏–Ω–Ω–∞", 'p.length AS "–î–ª–∏–Ω–Ω–∞"'),
            ("–®–∏—Ä–∏–Ω–∞", 'p.width AS "–®–∏—Ä–∏–Ω–∞"'),
            ("–í—ã—Å–æ—Ç–∞", 'p.height AS "–í—ã—Å–æ—Ç–∞"'),
            ("–í–µ—Å", 'p.weight AS "–í–µ—Å"'),
            ("–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", 'p.dimensions_str AS "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞"'),
            ("OE –Ω–æ–º–µ—Ä", 'pd.oe_list AS "OE –Ω–æ–º–µ—Ä"'),
            ("–∞–Ω–∞–ª–æ–≥–∏", 'aa.analog_list AS "–∞–Ω–∞–ª–æ–≥–∏"'),
            ("–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", 'p.image_url AS "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"'),
            ("–¶–µ–Ω–∞ —Å –Ω–∞—Ü–µ–Ω–∫–æ–π", 'p.price_with_markup AS "–¶–µ–Ω–∞ —Å –Ω–∞—Ü–µ–Ω–∫–æ–π"')
        ]

        if not selected_cols:
            selected_exprs = [expr for _, expr in columns_map]
        else:
            selected_exprs = []
            for name, expr in columns_map:
                if name in selected_cols:
                    selected_exprs.append(expr)
            if not selected_exprs:
                selected_exprs = [expr for _, expr in columns_map]

        query = f"""
        WITH DescriptionText AS (
            SELECT ' ' AS text
        ),
        pd AS (
            SELECT
                cr.artikul_norm,
                cr.brand_norm,
                STRING_AGG(DISTINCT regexp_replace(regexp_replace(o.oe_number, '''', ''), '[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\-\s]', '', 'g'), ', ') AS oe_list,
                ANY_VALUE(o.name) AS representative_name,
                ANY_VALUE(o.applicability) AS representative_applicability,
                ANY_VALUE(o.category) AS representative_category
            FROM cross_references cr
            JOIN oe_data o ON cr.oe_number_norm = o.oe_number_norm
            GROUP BY cr.artikul_norm, cr.brand_norm
        ),
        aa AS (
            SELECT
                cr1.artikul_norm,
                cr1.brand_norm,
                STRING_AGG(DISTINCT regexp_replace(regexp_replace(p2.artikul, '''', ''), '[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\-\s]', '', 'g'), ', ') as analog_list
            FROM cross_references cr1
            JOIN cross_references cr2 ON cr1.oe_number_norm = cr2.oe_number_norm
            JOIN parts_data p2 ON cr2.artikul_norm = p2.artikul_norm AND cr2.brand_norm = p2.brand_norm
            WHERE cr1.artikul_norm != p2.artikul_norm OR cr1.brand_norm != p2.brand_norm
            GROUP BY cr1.artikul_norm, cr1.brand_norm
        )
        SELECT
            {', '.join(selected_exprs)}
        FROM parts_data p
        LEFT JOIN pd ON p.artikul_norm = pd.artikul_norm AND p.brand_norm = pd.brand_norm
        LEFT JOIN aa ON p.artikul_norm = aa.artikul_norm AND p.brand_norm = aa.brand_norm
        LEFT JOIN DescriptionText dt ON 1=1
        {filter_where}
        {(' AND ' + exclude_where[6:]) if exclude_where else ''}
        ORDER BY p.brand, p.artikul
        """
        return query

    def export_csv(self, output_path, selected_cols=None, exclude_terms=None, filters=None):
        total = self.conn.execute("SELECT COUNT(*) FROM (SELECT DISTINCT artikul_norm, brand_norm FROM parts_data)").fetchone()[0]
        if total == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False
        query = self.build_export_query(selected_cols, exclude_terms, filters)
        df = self.conn.execute(query).pl()
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä—ã –∏ —Ü–µ–Ω—É
        for c in ["–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞", "–¶–µ–Ω–∞ —Å –Ω–∞—Ü–µ–Ω–∫–æ–π"]:
            if c in df.columns:
                df = df.with_columns(
                    pl.when(pl.col(c).is_not_null())
                    .then(pl.col(c).cast(pl.Utf8))
                    .otherwise("")
                    .alias(c)
                )
        buf = io.StringIO()
        df.write_csv(buf, separator=';')
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(buf.getvalue())
        st.success(f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {total:,} –∑–∞–ø–∏—Å–µ–π.")
        return True

    def export_excel(self, output_path: Path, selected_cols=None, exclude_terms=None, filters=None):
        total = self.conn.execute("SELECT COUNT(*) FROM (SELECT DISTINCT artikul_norm, brand_norm FROM parts_data)").fetchone()[0]
        if total == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False, None
        num_files = (total + EXCEL_ROW_LIMIT - 1) // EXCEL_ROW_LIMIT
        filenames = []
        for i in range(num_files):
            offset = i * EXCEL_ROW_LIMIT
            query = self.build_export_query(selected_cols, exclude_terms, filters) + f" LIMIT {EXCEL_ROW_LIMIT} OFFSET {offset}"
            df = self.conn.execute(query).pl()
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä—ã –∏ —Ü–µ–Ω—É
            for c in ["–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞", "–¶–µ–Ω–∞ —Å –Ω–∞—Ü–µ–Ω–∫–æ–π"]:
                if c in df.columns:
                    df = df.with_columns(
                        pl.when(pl.col(c).is_not_null())
                        .then(pl.col(c).cast(pl.Utf8))
                        .otherwise("")
                        .alias(c)
                    )
            filename = output_path.with_name(f"{output_path.stem}_part_{i+1}.xlsx")
            df.write_excel(str(filename))
            filenames.append(filename)
        if num_files > 1:
            zip_path = output_path.with_suffix('.zip')
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                for filename in filenames:
                    zipf.write(str(filename), filename.name)
                    os.remove(str(filename))
            return True, zip_path
        else:
            return True, filenames[0]

    def export_parquet(self, output_path, selected_cols=None, exclude_terms=None, filters=None):
        total = self.conn.execute("SELECT COUNT(*) FROM (SELECT DISTINCT artikul_norm, brand_norm FROM parts_data)").fetchone()[0]
        if total == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False
        query = self.build_export_query(selected_cols, exclude_terms, filters)
        df = self.conn.execute(query).pl()
        df.write_parquet(output_path)
        size_mb = os.path.getsize(output_path) / 1024 / 1024
        st.success(f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {total} –∑–∞–ø–∏—Å–µ–π. –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {size_mb:.2f} –ú–ë")
        return True

    def show_export_ui(self):
        st.header("üì§ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        total = self.conn.execute("SELECT COUNT(*) FROM (SELECT DISTINCT artikul_norm, brand_norm FROM parts_data)").fetchone()[0]
        if total == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞.")
            return

        # –§–∏–ª—å—Ç—Ä—ã
        st.subheader("–§–∏–ª—å—Ç—Ä—ã")
        brands = self.conn.execute("SELECT DISTINCT brand FROM parts_data").fetchdf()['brand'].dropna().tolist()
        selected_brands = st.multiselect("–ë—Ä–µ–Ω–¥—ã", options=brands)
        categories = self.conn.execute("SELECT DISTINCT category FROM oe_data").fetchdf()['category'].dropna().tolist()
        selected_categories = st.multiselect("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", options=categories)
        arts = self.conn.execute("SELECT DISTINCT artikul FROM parts_data").fetchdf()['artikul'].dropna().tolist()
        selected_arts = st.multiselect("–ê—Ä—Ç–∏–∫—É–ª—ã", options=arts)
        o_list = self.conn.execute("SELECT DISTINCT oe_number FROM oe_data").fetchdf()['oe_number'].dropna().tolist()
        selected_oes = st.multiselect("OE –Ω–æ–º–µ—Ä–∞", options=o_list)

        filters = {}
        if selected_brands:
            filters['brand'] = selected_brands
        if selected_categories:
            filters['category'] = selected_categories
        if selected_arts:
            filters['artikul'] = selected_arts
        if selected_oes:
            filters['oe'] = selected_oes

        # –ö–æ–ª–æ–Ω–∫–∏
        default_cols = [
            "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", "–ë—Ä–µ–Ω–¥", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", "–û–ø–∏—Å–∞–Ω–∏–µ",
            "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", "–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞", "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞",
            "OE –Ω–æ–º–µ—Ä", "–∞–Ω–∞–ª–æ–≥–∏", "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–¶–µ–Ω–∞ —Å –Ω–∞—Ü–µ–Ω–∫–æ–π"
        ]
        selected_cols = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞", options=default_cols, default=default_cols)

        format_choice = st.radio("–§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞", ["CSV", "Excel (.xlsx)", "Parquet"])
        if st.button("–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å"):
            filename = self.data_dir / "auto_parts_export"
            if format_choice == "CSV":
                full_path = filename.with_suffix('.csv')
                self.export_csv(str(full_path), selected_cols, exclude_terms=None, filters=filters)
                with open(str(full_path), "rb") as f:
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å CSV", f, "auto_parts_export.csv", "text/csv")
            elif format_choice == "Excel (.xlsx)":
                success, out_path = self.export_excel(filename, selected_cols, exclude_terms=None, filters=filters)
                if success and out_path:
                    with open(str(out_path), "rb") as f:
                        st.download_button("üì• –°–∫–∞—á–∞—Ç—å Excel", f, out_path.name, "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            else:
                out_path = filename.with_suffix('.parquet')
                self.export_parquet(str(out_path), selected_cols, exclude_terms=None, filters=filters)
                with open(str(out_path), "rb") as f:
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å Parquet", f, "auto_parts_export.parquet", "application/octet-stream")

    def show_settings_ui(self):
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        st.subheader("–ù–∞—Ü–µ–Ω–∫–∏")
        new_markup = st.slider("–û–±—â–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ (%)", 0.0, 100.0, value=self.get_global_markup(), step=0.5)
        if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å –æ–±—â—É—é –Ω–∞—Ü–µ–Ω–∫—É"):
            self.set_global_markup(new_markup)
            st.success(f"–û–±—â–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ {new_markup}%")
        # –î–ª—è –±—Ä–µ–Ω–¥–æ–≤
        st.subheader("–ù–∞—Ü–µ–Ω–∫–∏ –ø–æ –±—Ä–µ–Ω–¥–∞–º")
        brands = self.conn.execute("SELECT DISTINCT brand FROM parts_data").fetchdf()['brand'].dropna().tolist()
        for b in brands:
            current_markup = self.get_brand_markup(b)
            new_b_markup = st.slider(f"–ù–∞—Ü–µ–Ω–∫–∞ –¥–ª—è '{b}'", 0.0, 100.0, value=current_markup, step=0.5)
            if st.button(f"–ü—Ä–∏–º–µ–Ω–∏—Ç—å –¥–ª—è {b}"):
                self.set_brand_markup(b, new_b_markup)
                st.success(f"–ù–∞—Ü–µ–Ω–∫–∞ –¥–ª—è {b} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ {new_b_markup}%")
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ü–µ–Ω
        st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ —Ü–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞")
        uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å Excel —Ñ–∞–π–ª —Å —Ü–µ–Ω–∞–º–∏", type=['xlsx','xls'])
        if uploaded:
            df_prices = pl.read_excel(uploaded)
            self.save_recommended_prices(df_prices)
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
        st.subheader("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏")
        key_input = st.text_input("–ö–ª—é—á (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'engine')")
        name_input = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
        if st.button("–î–æ–±–∞–≤–∏—Ç—å/–û–±–Ω–æ–≤–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é"):
            if key_input and name_input:
                self.categories[key_input] = name_input
                st.success(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è '{name_input}' –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∞.")
        st.write("–¢–µ–∫—É—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:")
        for k, v in self.categories.items():
            st.write(f"{k}: {v}")

    def delete_brand(self, brand_norm):
        count = self.conn.execute("DELETE FROM parts_data WHERE brand_norm=?", [brand_norm]).fetchone()[0]
        self.conn.execute("DELETE FROM cross_references WHERE (artikul_norm, brand_norm) NOT IN (SELECT DISTINCT artikul_norm, brand_norm FROM parts_data)")
        return count

    def delete_artikul(self, artikul_norm):
        count = self.conn.execute("DELETE FROM parts_data WHERE artikul_norm=?", [artikul_norm]).fetchone()[0]
        self.conn.execute("DELETE FROM cross_references WHERE (artikul_norm, brand_norm) NOT IN (SELECT DISTINCT artikul_norm, brand_norm FROM parts_data)")
        return count

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    st.title("üöó –ü–æ–ª–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç—è–º–∏")
    st.markdown("""
    ### üõ†Ô∏è –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–µ–π
    - –ì–∏–±–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω–∞–º–∏, –Ω–∞—Ü–µ–Ω–∫–∞–º–∏ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
    - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
    - –£–¥–æ–±–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏ –∏ –±—Ä–µ–Ω–¥–∞–º–∏
    - –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
    """)

    catalog = AutoPartsCatalog()

    menu = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", ["–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", "–ù–∞—Å—Ç—Ä–æ–π–∫–∏", "–≠–∫—Å–ø–æ—Ä—Ç", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ"])

    if menu == "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö":
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
        st.header("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
        total_parts = catalog.get_total_parts()
        if total_parts == 0:
            st.warning("–ë–∞–∑–∞ –ø—É—Å—Ç–∞. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤—Å–µ —Ñ–∞–π–ª—ã –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.")
        else:
            st.info("–ë–∞–∑–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ. –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å —Ñ–∞–π–ª—ã.")
        col1, col2 = st.columns(2)
        with col1:
            file_oe = st.file_uploader("–û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OE)", type=['xlsx', 'xls'])
            file_cross = st.file_uploader("–ö—Ä–æ—Å—Å—ã", type=['xlsx', 'xls'])
            file_prices = st.file_uploader("–¶–µ–Ω—ã (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ)", type=['xlsx', 'xls'])
        with col2:
            file_dim = st.file_uploader("–í–µ—Å–æ–≥–∞–±–∞—Ä–∏—Ç—ã", type=['xlsx', 'xls'])
            file_img = st.file_uploader("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", type=['xlsx', 'xls'])
        files_map = {
            'oe': file_oe,
            'cross': file_cross,
            'dimensions': file_dim,
            'images': file_img,
            'prices': file_prices
        }
        if st.button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª—ã"):
            dfs = {}
            for key, file in files_map.items():
                if file:
                    path = catalog.data_dir / f"{key}_{int(time.time())}.xlsx"
                    with open(path, 'wb') as f:
                        f.write(file.read())
                    df = catalog.read_and_prepare_file(str(path), key)
                    dfs[key] = df
            catalog.process_and_load(dfs)

    elif menu == "–ù–∞—Å—Ç—Ä–æ–π–∫–∏":
        catalog.show_settings_ui()

    elif menu == "–≠–∫—Å–ø–æ—Ä—Ç":
        catalog.show_export_ui()

    elif menu == "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
        stats = catalog.get_statistics()
        st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        st.metric("–ê—Ä—Ç–∏–∫—É–ª–æ–≤", stats['total_parts'])
        st.metric("OE", stats['total_oe'])
        st.metric("–ë—Ä–µ–Ω–¥–æ–≤", stats['total_brands'])
        st.subheader("–¢–æ–ø –±—Ä–µ–Ω–¥–æ–≤")
        st.dataframe(stats['top_brands'])
        st.subheader("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏")
        st.dataframe(stats['categories'])

    elif menu == "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ":
        st.header("üóëÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏")
        action = st.radio("–î–µ–π—Å—Ç–≤–∏–µ", ["–£–¥–∞–ª–∏—Ç—å –ø–æ –±—Ä–µ–Ω–¥—É", "–£–¥–∞–ª–∏—Ç—å –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É", "–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ü–µ–Ω—ã"])
        if action == "–£–¥–∞–ª–∏—Ç—å –ø–æ –±—Ä–µ–Ω–¥—É":
            brands = catalog.conn.execute("SELECT DISTINCT brand FROM parts_data").fetchdf()['brand'].dropna().tolist()
            if not brands:
                st.info("–ù–µ—Ç –±—Ä–µ–Ω–¥–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")
            else:
                brand = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –±—Ä–µ–Ω–¥ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è", brands)
                norm_b = catalog.conn.execute("SELECT brand_norm FROM parts_data WHERE brand=?", [brand]).fetchone()
                if norm_b:
                    norm_b = norm_b[0]
                else:
                    norm_b = catalog.normalize_key(pl.Series([brand]))[0]
                count = catalog.delete_brand(norm_b)
                st.success(f"–£–¥–∞–ª–µ–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π –ø–æ –±—Ä–µ–Ω–¥—É {brand}")
        elif action == "–£–¥–∞–ª–∏—Ç—å –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É":
            artikul_input = st.text_input("–í–≤–µ–¥–∏—Ç–µ –∞—Ä—Ç–∏–∫—É–ª –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
            if artikul_input:
                norm_a = catalog.normalize_key(pl.Series([artikul_input]))[0]
                count = catalog.delete_artikul(norm_a)
                st.success(f"–£–¥–∞–ª–µ–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É {artikul_input}")
        elif action == "–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ü–µ–Ω—ã":
            st.subheader("–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ü–µ–Ω—É")
            artikul_edit = st.text_input("–ê—Ä—Ç–∏–∫—É–ª")
            brand_edit = st.text_input("–ë—Ä–µ–Ω–¥")
            price_edit = st.number_input("–¶–µ–Ω–∞", min_value=0.0, step=0.01)
            if st.button("–û–±–Ω–æ–≤–∏—Ç—å —Ü–µ–Ω—É"):
                catalog.conn.execute(
                    "INSERT OR REPLACE INTO prices (artikul, recommended_price, brand) VALUES (?, ?, ?)",
                    [artikul_edit, price_edit, brand_edit]
                )
                st.success(f"–¶–µ–Ω–∞ –¥–ª—è {artikul_edit} ({brand_edit}) –æ–±–Ω–æ–≤–ª–µ–Ω–∞.")

if __name__ == "__main__":
    main()
