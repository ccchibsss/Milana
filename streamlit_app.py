import platform
import sys
import polars as pl
import duckdb
import streamlit as st
import os
import time
import io
import zipfile
from pathlib import Path
from typing import Dict, List

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Python (—Ç—Ä–µ–±—É–µ—Ç—Å—è 64-bit)
if platform.architecture()[0] != '64bit':
    error_msg = """
    ‚ùå –û–®–ò–ë–ö–ê: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ 32-bit –≤–µ—Ä—Å–∏—è Python!
    –≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç 64-bit –≤–µ—Ä—Å–∏—é Python, —Ç–∞–∫ –∫–∞–∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ 
    pyarrow, polars –∏ duckdb –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç 32-bit –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–∞ Windows.
    –†–µ—à–µ–Ω–∏–µ:
    1. –°–∫–∞—á–∞–π—Ç–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ 64-bit Python —Å https://www.python.org/downloads/
    2. –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install -r requirements.txt
    3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å–Ω–æ–≤–∞
    –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {}
    """.format(platform.architecture()[0])
    print(error_msg)
    sys.exit(1)

import warnings
warnings.filterwarnings('ignore')

EXCEL_ROW_LIMIT = 1_000_000

class HighVolumeAutoPartsCatalog:
    def __init__(self):
        self.data_dir = Path("./auto_parts_data")
        self.data_dir.mkdir(exist_ok=True)
        self.db_path = self.data_dir / "catalog.duckdb"
        self.conn = duckdb.connect(str(self.db_path))
        self.setup_database()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–∫–∏
        self.overall_markup = 0.0  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        self.brand_markups: Dict[str, float] = {}  # –ø–æ –±—Ä–µ–Ω–¥–∞–º

        st.set_page_config(
            page_title="AutoParts Catalog 10M+", 
            layout="wide",
            page_icon="üöó"
        )

    def setup_database(self):
        # –¢–∞–±–ª–∏—Ü–∞ —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º –∏ –ø—Ä–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS oe_data (
                oe_number_norm VARCHAR PRIMARY KEY,
                oe_number VARCHAR,
                name VARCHAR,
                applicability VARCHAR,
                category VARCHAR
            )
        """)
        # –¢–∞–±–ª–∏—Ü–∞ —Å –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS parts_data (
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                artikul VARCHAR,
                brand VARCHAR,
                multiplicity INTEGER,
                barcode VARCHAR,
                length DOUBLE, 
                width DOUBLE,
                height DOUBLE, 
                weight DOUBLE,
                image_url VARCHAR,
                dimensions_str VARCHAR,
                description VARCHAR,
                PRIMARY KEY (artikul_norm, brand_norm)
            )
        """)
        # –¢–∞–±–ª–∏—Ü–∞ —Å –∫—Ä–æ—Å—Å–∞–º–∏
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS cross_references (
                oe_number_norm VARCHAR,
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                PRIMARY KEY (oe_number_norm, artikul_norm, brand_norm)
            )
        """)
        # –¢–∞–±–ª–∏—Ü–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS recommended_prices (
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                recommended_price DOUBLE,
                PRIMARY KEY (artikul_norm, brand_norm)
            )
        """)

    def create_indexes(self):
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_oe_data_oe ON oe_data(oe_number_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_parts_data_keys ON parts_data(artikul_norm, brand_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_cross_oe ON cross_references(oe_number_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_cross_artikul ON cross_references(artikul_norm, brand_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_recommended_prices ON recommended_prices(artikul_norm, brand_norm)")

    @staticmethod
    def normalize_key(key_series: pl.Series) -> pl.Series:
        return (
            key_series
            .fill_null("")
            .cast(pl.Utf8)
            .str.replace_all("'", "")
            .str.replace_all(r"[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\-\s]", "")
            .str.replace_all(r"\s+", " ")
            .str.strip_chars()
            .str.to_lowercase()
        )

    def upsert_recommended_prices(self, df: pl.DataFrame):
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–ª–∏ –≤—Å—Ç–∞–≤–∫–∞ —Ü–µ–Ω
        df = df.with_columns(
            artikul_norm=self.normalize_key(pl.col('artikul')),
            brand_norm=self.normalize_key(pl.col('brand')),
            recommended_price=pl.col('recommended_price').cast(pl.Float64)
        )
        # UPSERT
        for row in df.iter_rows():
            self.conn.execute("""
                INSERT INTO recommended_prices (artikul_norm, brand_norm, recommended_price)
                VALUES (?, ?, ?)
                ON CONFLICT (artikul_norm, brand_norm) DO UPDATE SET recommended_price=excluded.recommended_price
            """, [row[1], row[2], row[3]])

    def load_recommended_prices(self, file_path: str):
        df = pl.read_excel(file_path, engine='calamine')
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: –∞—Ä—Ç–∏–∫—É–ª, –±—Ä–µ–Ω–¥, —Ü–µ–Ω–∞
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è –≤ –Ω–∞–ª–∏—á–∏–∏ –∫–æ–ª–æ–Ω–æ–∫
        df = df.rename({df.columns[0]: 'artikul', df.columns[1]: 'brand', df.columns[2]: 'recommended_price'})
        self.upsert_recommended_prices(df)

    def set_markup(self, overall: float, brand_markups: Dict[str, float]):
        self.overall_markup = overall
        self.brand_markups = brand_markups

    def get_brand_markup(self, brand_norm: str) -> float:
        return self.brand_markups.get(brand_norm, self.overall_markup)

    def build_export_query(self, selected_columns: List[str] | None, exclude_terms: str = "") -> str:
        # –í–≤–æ–¥–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        # –°–æ–∑–¥–∞–µ–º CTE —Å —Ç–µ–∫—Å—Ç–æ–º –æ–ø–∏—Å–∞–Ω–∏—è
        standard_description = """–°–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: –Ω–æ–≤—ã–π (–≤ —É–ø–∞–∫–æ–≤–∫–µ).
–í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–∏ –∏ –∞–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã ‚Äî –Ω–∞–¥–µ–∂–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –≤–∞—à–µ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è. 
–û–±–µ—Å–ø–µ—á—å—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, –¥–æ–ª–≥–æ–≤–µ—á–Ω–æ—Å—Ç—å –∏ –≤—ã—Å–æ–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∞—à–µ–≥–æ –∞–≤—Ç–æ —Å –ø–æ–º–æ—â—å—é –Ω–∞—à–µ–≥–æ —à–∏—Ä–æ–∫–æ–≥–æ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã—Ö –∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–µ–π.

–í –Ω–∞—à–µ–º –∫–∞—Ç–∞–ª–æ–≥–µ –≤—ã –Ω–∞–π–¥–µ—Ç–µ —Ç–æ—Ä–º–æ–∑–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã, —Ñ–∏–ª—å—Ç—Ä—ã (–º–∞—Å–ª—è–Ω—ã–µ, –≤–æ–∑–¥—É—à–Ω—ã–µ, —Å–∞–ª–æ–Ω–Ω—ã–µ), —Å–≤–µ—á–∏ –∑–∞–∂–∏–≥–∞–Ω–∏—è, —Ä–∞—Å—Ö–æ–¥–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –∞–≤—Ç–æ—Ö–∏–º–∏—é, —ç–ª–µ–∫—Ç—Ä–∏–∫—É, –∞–≤—Ç–æ–º–∞—Å–ª–∞, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∞ —Ç–∞–∫–∂–µ –¥—Ä—É–≥–∏–µ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏–µ, –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. 

–ú—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –±—ã—Å—Ç—Ä—É—é –¥–æ—Å—Ç–∞–≤–∫—É, –≤—ã–≥–æ–¥–Ω—ã–µ —Ü–µ–Ω—ã –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –¥–ª—è –ª—é–±–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ ‚Äî –∞–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—è, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –∏–ª–∏ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–∞. 

–í—ã–±–∏—Ä–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ –ª—É—á—à–µ–µ ‚Äî –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç –≤–µ–¥—É—â–∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π."""
        # –§–æ—Ä–º–∏—Ä—É–µ–º —É—Å–ª–æ–≤–∏—è –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        exclude_sql = ""
        params = []

        if exclude_terms:
            terms = [term.strip() for term in exclude_terms.split('|') if term.strip()]
            # —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            for term in terms:
                exclude_sql += " AND r.\"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\" NOT IN ({})".format(', '.join(['?']*len(terms)))
                params.extend(terms)
            # —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            for term in terms:
                exclude_sql += " AND r.\"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\" NOT LIKE ?"
                params.append(f"%{term}%")

        # –§–æ—Ä–º–∏—Ä—É–µ–º SELECT –≤—ã—Ä–∞–∂–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        columns_map = [
            ("–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", 'r.artikul AS "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞"'),
            ("–ë—Ä–µ–Ω–¥", 'r.brand AS "–ë—Ä–µ–Ω–¥"'),
            ("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", 'COALESCE(r.representative_name, r.analog_representative_name) AS "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ"'),
            ("–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", 'COALESCE(r.representative_applicability, r.analog_representative_applicability) AS "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å"'),
            ("–û–ø–∏—Å–∞–Ω–∏–µ", "CONCAT(COALESCE(r.description, ''), dt.text) AS \"–û–ø–∏—Å–∞–Ω–∏–µ\""),
            ("–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞", 'COALESCE(r.representative_category, r.analog_representative_category) AS "–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞"'),
            ("–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", 'r.multiplicity AS "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å"'),
            ("–î–ª–∏–Ω–Ω–∞", 'COALESCE(r.length, r.analog_length) AS "–î–ª–∏–Ω–Ω–∞"'),
            ("–®–∏—Ä–∏–Ω–∞", 'COALESCE(r.width, r.analog_width) AS "–®–∏—Ä–∏–Ω–∞"'),
            ("–í—ã—Å–æ—Ç–∞", 'COALESCE(r.height, r.analog_height) AS "–í—ã—Å–æ—Ç–∞"'),
            ("–í–µ—Å", 'COALESCE(r.weight, r.analog_weight) AS "–í–µ—Å"'),
            ("–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "COALESCE(CASE WHEN r.dimensions_str IS NULL OR r.dimensions_str = '' OR UPPER(TRIM(r.dimensions_str)) = 'XX' THEN NULL ELSE r.dimensions_str END, r.analog_dimensions_str) AS \"–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞\""),
            ("OE –Ω–æ–º–µ—Ä", 'r.oe_list AS "OE –Ω–æ–º–µ—Ä"'),
            ("–∞–Ω–∞–ª–æ–≥–∏", 'r.analog_list AS "–∞–Ω–∞–ª–æ–≥–∏"'),
            ("–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", 'r.image_url AS "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"'),
            ("–§–∏–Ω–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞", 'r.final_price AS "–¶–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏"')
        ]

        if not selected_columns:
            selected_exprs = [expr for _, expr in columns_map]
        else:
            selected_exprs = [expr for name, expr in columns_map if name in selected_columns]
            if not selected_exprs:
                selected_exprs = [expr for _, expr in columns_map]

        # CTE —Å —Ç–µ–∫—Å—Ç–æ–º
        ctes = f"""
        WITH DescriptionTemplate AS (
            SELECT CHR(10) || CHR(10) || $${standard_description}$$ AS text
        ),
        PartDetails AS (
            SELECT
                cr.artikul_norm,
                cr.brand_norm,
                STRING_AGG(DISTINCT regexp_replace(regexp_replace(o.oe_number, '''', ''), '[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\\-\\s]', '', 'g'), ', ') AS oe_list,
                ANY_VALUE(o.name) AS representative_name,
                ANY_VALUE(o.applicability) AS representative_applicability,
                ANY_VALUE(o.category) AS representative_category
            FROM cross_references cr
            JOIN oe_data o ON cr.oe_number_norm = o.oe_number_norm
            GROUP BY cr.artikul_norm, cr.brand_norm
        ),
        AllAnalogs AS (
            SELECT
                cr1.artikul_norm,
                cr1.brand_norm,
                STRING_AGG(DISTINCT regexp_replace(regexp_replace(p2.artikul, '''', ''), '[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\\-\\s]', '', 'g'), ', ') as analog_list
            FROM cross_references cr1
            JOIN cross_references cr2 ON cr1.oe_number_norm = cr2.oe_number_norm
            JOIN parts_data p2 ON cr2.artikul_norm = p2.artikul_norm AND cr2.brand_norm = p2.brand_norm
            WHERE (cr1.artikul_norm != p2.artikul_norm OR cr1.brand_norm != p2.brand_norm)
            GROUP BY cr1.artikul_norm, cr1.brand_norm
        ),
        InitialOENumbers AS (
            SELECT DISTINCT
                p.artikul_norm,
                p.brand_norm,
                cr.oe_number_norm
            FROM parts_data p
            LEFT JOIN cross_references cr ON p.artikul_norm = cr.artikul_norm AND p.brand_norm = cr.brand_norm
            WHERE cr.oe_number_norm IS NOT NULL
        ),
        Level1Analogs AS (
            SELECT DISTINCT
                i.artikul_norm AS source_artikul_norm,
                i.brand_norm AS source_brand_norm,
                cr2.artikul_norm AS related_artikul_norm,
                cr2.brand_norm AS related_brand_norm
            FROM InitialOENumbers i
            JOIN cross_references cr2 ON i.oe_number_norm = cr2.oe_number_norm
            WHERE NOT (i.artikul_norm = cr2.artikul_norm AND i.brand_norm = cr2.brand_norm)
        ),
        Level1OENumbers AS (
            SELECT DISTINCT
                l1.source_artikul_norm,
                l1.source_brand_norm,
                cr3.oe_number_norm
            FROM Level1Analogs l1
            JOIN cross_references cr3 ON l1.related_artikul_norm = cr3.artikul_norm 
                                        AND l1.related_brand_norm = cr3.brand_norm
            WHERE NOT EXISTS (
                SELECT 1 FROM InitialOENumbers i 
                WHERE i.artikul_norm = l1.source_artikul_norm 
                AND i.brand_norm = l1.source_brand_norm 
                AND i.oe_number_norm = cr3.oe_number_norm
            )
        ),
        Level2Analogs AS (
            SELECT DISTINCT
                loe.source_artikul_norm,
                loe.source_brand_norm,
                cr4.artikul_norm AS related_artikul_norm,
                cr4.brand_norm AS related_brand_norm
            FROM Level1OENumbers loe
            JOIN cross_references cr4 ON loe.oe_number_norm = cr4.oe_number_norm
            WHERE NOT (loe.source_artikul_norm = cr4.artikul_norm AND loe.source_brand_norm = cr4.brand_norm)
        ),
        AllRelatedParts AS (
            SELECT DISTINCT source_artikul_norm, source_brand_norm, related_artikul_norm, related_brand_norm
            FROM Level1Analogs
            UNION
            SELECT DISTINCT source_artikul_norm, source_brand_norm, related_artikul_norm, related_brand_norm
            FROM Level2Analogs
        ),
        AggregatedAnalogData AS (
            SELECT
                arp.source_artikul_norm AS artikul_norm,
                arp.source_brand_norm AS brand_norm,
                MAX(CASE WHEN p2.length IS NOT NULL THEN p2.length ELSE NULL END) AS length,
                MAX(CASE WHEN p2.width IS NOT NULL THEN p2.width ELSE NULL END) AS width,
                MAX(CASE WHEN p2.height IS NOT NULL THEN p2.height ELSE NULL END) AS height,
                MAX(CASE WHEN p2.weight IS NOT NULL THEN p2.weight ELSE NULL END) AS weight,
                ANY_VALUE(CASE WHEN p2.dimensions_str IS NOT NULL 
                               AND p2.dimensions_str != '' 
                               AND UPPER(TRIM(p2.dimensions_str)) != 'XX' 
                          THEN p2.dimensions_str ELSE NULL END) AS dimensions_str,
                ANY_VALUE(CASE WHEN pd2.representative_name IS NOT NULL AND pd2.representative_name != '' THEN pd2.representative_name ELSE NULL END) AS representative_name,
                ANY_VALUE(CASE WHEN pd2.representative_applicability IS NOT NULL AND pd2.representative_applicability != '' THEN pd2.representative_applicability ELSE NULL END) AS representative_applicability,
                ANY_VALUE(CASE WHEN pd2.representative_category IS NOT NULL AND pd2.representative_category != '' THEN pd2.representative_category ELSE NULL END) AS representative_category
            FROM AllRelatedParts arp
            JOIN parts_data p2 ON arp.related_artikul_norm = p2.artikul_norm AND arp.related_brand_norm = p2.brand_norm
            LEFT JOIN PartDetails pd2 ON p2.artikul_norm = pd2.artikul_norm AND p2.brand_norm = pd2.brand_norm
            GROUP BY arp.source_artikul_norm, arp.source_brand_norm
        ),
        RankedData AS (
            SELECT
                p.artikul,
                p.brand,
                p.description,
                p.multiplicity,
                p.length,
                p.width,
                p.height,
                p.weight,
                p.dimensions_str,
                p.image_url,
                pd.representative_name,
                pd.representative_applicability,
                pd.representative_category,
                pd.oe_list,
                aa.analog_list,
                p_analog.length AS analog_length,
                p_analog.width AS analog_width,
                p_analog.height AS analog_height,
                p_analog.weight AS analog_weight,
                p_analog.dimensions_str AS analog_dimensions_str,
                p_analog.representative_name AS analog_representative_name,
                p_analog.representative_applicability AS analog_representative_applicability,
                p_analog.representative_category AS analog_representative_category,
                ROW_NUMBER() OVER(PARTITION BY p.artikul_norm, p.brand_norm ORDER BY pd.representative_name DESC NULLS LAST, pd.oe_list DESC NULLS LAST) as rn,
                -- –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã
                -- –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—É —Ü–µ–Ω
                -- –í –æ—Å–Ω–æ–≤–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ —Å–¥–µ–ª–∞–µ–º JOIN —Å —Ç–∞–±–ª–∏—Ü–µ–π —Ü–µ–Ω –∏ —Ä–∞—Å—á–µ—Ç
                -- –í —ç—Ç–æ–º –º–µ—Å—Ç–µ –æ—Å—Ç–∞–≤–∏–º placeholder
                0 AS final_price
            FROM parts_data p
            LEFT JOIN PartDetails pd ON p.artikul_norm = pd.artikul_norm AND p.brand_norm = pd.brand_norm
            LEFT JOIN AllAnalogs aa ON p.artikul_norm = aa.artikul_norm AND p.brand_norm = aa.brand_norm
            LEFT JOIN AggregatedAnalogData p_analog ON p.artikul_norm = p_analog.artikul_norm AND p.brand_norm = p_analog.brand_norm
        )
        """

        # –í –æ—Å–Ω–æ–≤–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ —Å–¥–µ–ª–∞–µ–º JOIN —Å —Ü–µ–Ω–∞–º–∏
        # –í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤–∏–º —Ä–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã
        query = f"""
        {ctes}
        SELECT
            {', '.join(selected_exprs)}
        FROM RankedData r
        LEFT JOIN recommended_prices rp ON r.artikul_norm = rp.artikul_norm AND r.brand_norm = rp.brand_norm
        LEFT JOIN parts_data p ON r.artikul_norm = p.artikul_norm AND r.brand_norm = p.brand_norm
        LEFT JOIN (
            SELECT *,
            -- —Ä–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏
            COALESCE(rp.recommended_price, 0) * (1 + {self.overall_markup / 100}) * (1 + self.get_brand_markup('r.brand')/100) AS final_price
            FROM parts_data p2
            LEFT JOIN recommended_prices rp ON p2.artikul_norm = rp.artikul_norm AND p2.brand_norm = rp.brand_norm
        ) p2 ON r.artikul_norm = p2.artikul_norm AND r.brand_norm = p2.brand_norm
        WHERE r.rn = 1
        {exclude_sql}
        ORDER BY r.brand, r.artikul
        """
        return query, params

    def export_to_csv_optimized(self, output_path: str, selected_columns: List[str] | None = None, exclude_terms: str = "") -> bool:
        total_records = self.conn.execute("SELECT COUNT(*) FROM (SELECT DISTINCT artikul_norm, brand_norm FROM parts_data) AS t").fetchone()[0]
        if total_records == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False
        st.info(f"üì§ –≠–∫—Å–ø–æ—Ä—Ç {total_records:,} –∑–∞–ø–∏—Å–µ–π –≤ CSV...")
        try:
            query, params = self.build_export_query(selected_columns, exclude_terms)
            df = self.conn.execute(query, params).pl()

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            for col_name in ["–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞", "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å"]:
                if col_name in df.columns:
                    df = df.with_columns(
                        pl.when(pl.col(col_name).is_not_null())
                        .then(pl.col(col_name).cast(pl.Utf8))
                        .otherwise(pl.lit(""))
                        .alias(col_name)
                    )

            buf = io.StringIO()
            df.write_csv(buf, separator=';')
            csv_text = buf.getvalue()

            with open(output_path, 'wb') as f:
                f.write(b'\xef\xbb\xbf')
                f.write(csv_text.encode('utf-8'))

            file_size = os.path.getsize(output_path) / (1024 * 1024)
            st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ CSV: {output_path} ({file_size:.1f} –ú–ë)")
            return True
        except Exception as e:
            print(e)
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ CSV: {e}")
            return False

    def show_export_interface(self):
        st.header("üì§ –£–º–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        total_records = self.conn.execute("SELECT count(DISTINCT (artikul_norm, brand_norm)) FROM parts_data").fetchone()[0]
        st.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {total_records:,}")
        if total_records == 0:
            st.warning("–ë–∞–∑–∞ –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return

        # –í–≤–æ–¥ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        exclude_terms = st.text_input("–ò—Å–∫–ª—é—á–∏—Ç—å –ø–æ–∑–∏—Ü–∏–∏ (—á–µ—Ä–µ–∑ |):", value="")
        selected_columns = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞", options=[
            "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", "–ë—Ä–µ–Ω–¥", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", "–û–ø–∏—Å–∞–Ω–∏–µ",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", "–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞",
            "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "OE –Ω–æ–º–µ—Ä", "–∞–Ω–∞–ª–æ–≥–∏", "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–¶–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏"
        ], default=[
            "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", "–ë—Ä–µ–Ω–¥", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", "–û–ø–∏—Å–∞–Ω–∏–µ",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", "–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞",
            "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "OE –Ω–æ–º–µ—Ä", "–∞–Ω–∞–ª–æ–≥–∏", "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–¶–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏"
        ])

        export_format = st.radio("–§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞:", ["CSV", "Excel (.xlsx)", "Parquet"], index=0)

        if st.button("üöÄ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å", type="primary"):
            output_path = self.data_dir / "auto_parts_export"
            if export_format == "CSV":
                out_file = str(output_path.with_suffix('.csv'))
                with st.spinner("–≠–∫—Å–ø–æ—Ä—Ç –≤ CSV..."):
                    self.export_to_csv_optimized(out_file, selected_columns, exclude_terms)
                with open(out_file, "rb") as f:
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å CSV", f, "auto_parts_export.csv", "text/csv")
            elif export_format == "Excel (.xlsx)":
                out_file = output_path.with_suffix('.xlsx')
                with st.spinner("–≠–∫—Å–ø–æ—Ä—Ç –≤ Excel..."):
                    self.export_to_excel(out_file, selected_columns, exclude_terms)
                with open(out_file, "rb") as f:
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å Excel", f, "auto_parts_export.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            elif export_format == "Parquet":
                out_file = str(output_path.with_suffix('.parquet'))
                with st.spinner("–≠–∫—Å–ø–æ—Ä—Ç –≤ Parquet..."):
                    self.export_to_parquet(out_file, selected_columns, exclude_terms)
                with open(out_file, "rb") as f:
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å Parquet", f, "auto_parts_export.parquet", "application/octet-stream")
 
    def export_to_excel(self, output_path: Path, selected_columns: List[str], exclude_terms: str):
        total_records = self.conn.execute("SELECT COUNT(DISTINCT (artikul_norm, brand_norm)) FROM parts_data").fetchone()[0]
        if total_records == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False
        num_files = (total_records + EXCEL_ROW_LIMIT - 1) // EXCEL_ROW_LIMIT
        for i in range(num_files):
            query, params = self.build_export_query(selected_columns, exclude_terms)
            df = self.conn.execute(f"{query} LIMIT {EXCEL_ROW_LIMIT} OFFSET {i*EXCEL_ROW_LIMIT}", params).pl()
            # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–∞
            for col_name in ["–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞", "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å"]:
                if col_name in df.columns:
                    df = df.with_columns(
                        pl.when(pl.col(col_name).is_not_null())
                        .then(pl.col(col_name).cast(pl.Utf8))
                        .otherwise(pl.lit(""))
                        .alias(col_name)
                    )
            file_part_path = output_path.with_name(f"{output_path.stem}_part_{i+1}.xlsx")
            df.write_excel(str(file_part_path))
        # ZIP –µ—Å–ª–∏ –±–æ–ª—å—à–µ 1 —Ñ–∞–π–ª–∞
        # (–º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å)
        return True

    def export_to_parquet(self, output_path: str, selected_columns: List[str], exclude_terms: str):
        query, params = self.build_export_query(selected_columns, exclude_terms)
        df = self.conn.execute(query, params).pl()
        df.write_parquet(output_path)
        return True

    def build_export_query(self, selected_columns: List[str], exclude_terms: str):
        # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É SQL –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        query, params = self._build_full_query(selected_columns, exclude_terms)
        return query, params

    def _build_full_query(self, selected_columns: List[str], exclude_terms: str):
        # –¢—É—Ç —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –ø–æ–ª–Ω—ã–π SQL —Å —É—á–µ—Ç–æ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        # –í —ç—Ç–æ–º –º–µ—Å—Ç–µ –≤—Å—Ç—Ä–æ–∏–º –≤—Å–µ –≤—ã—à–µ–æ–ø–∏—Å–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        # –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏, –ø—Ä–∏–º–µ—Ä —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π:
        columns_map = [
            ("–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", 'p.artikul AS "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞"'),
            ("–ë—Ä–µ–Ω–¥", 'p.brand AS "–ë—Ä–µ–Ω–¥"'),
            ("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", 'COALESCE(p.description, "") AS "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ"'),
            ("–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", '"" AS "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å"'),
            ("–û–ø–∏—Å–∞–Ω–∏–µ", 'CONCAT(COALESCE(p.description, ""), dt.text) AS "–û–ø–∏—Å–∞–Ω–∏–µ"'),
            ("–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞", '"" AS "–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞"'),
            ("–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", 'p.multiplicity AS "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å"'),
            ("–î–ª–∏–Ω–Ω–∞", 'p.length AS "–î–ª–∏–Ω–Ω–∞"'),
            ("–®–∏—Ä–∏–Ω–∞", 'p.width AS "–®–∏—Ä–∏–Ω–∞"'),
            ("–í—ã—Å–æ—Ç–∞", 'p.height AS "–í—ã—Å–æ—Ç–∞"'),
            ("–í–µ—Å", 'p.weight AS "–í–µ—Å"'),
            ("–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", 'p.dimensions_str AS "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞"'),
            ("OE –Ω–æ–º–µ—Ä", 'p.oe_list AS "OE –Ω–æ–º–µ—Ä"'),
            ("–∞–Ω–∞–ª–æ–≥–∏", 'p.analog_list AS "–∞–Ω–∞–ª–æ–≥–∏"'),
            ("–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", 'p.image_url AS "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"'),
            ("–¶–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏", 'r.final_price AS "–¶–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏"')
        ]

        if not selected_columns:
            select_exprs = [expr for _, expr in columns_map]
        else:
            select_exprs = [expr for name, expr in columns_map if name in selected_columns]
            if not select_exprs:
                select_exprs = [expr for _, expr in columns_map]

        # –ü–æ–ª–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        sql = f"""
        WITH DescriptionTemplate AS (
            SELECT CHR(10) || CHR(10) || $${"""–°–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: –Ω–æ–≤—ã–π (–≤ —É–ø–∞–∫–æ–≤–∫–µ).
–í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–∏ –∏ –∞–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã ‚Äî –Ω–∞–¥–µ–∂–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –≤–∞—à–µ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è. 
–û–±–µ—Å–ø–µ—á—å—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, –¥–æ–ª–≥–æ–≤–µ—á–Ω–æ—Å—Ç—å –∏ –≤—ã—Å–æ–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∞—à–µ–≥–æ –∞–≤—Ç–æ —Å –ø–æ–º–æ—â—å—é –Ω–∞—à–µ–≥–æ —à–∏—Ä–æ–∫–æ–≥–æ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã—Ö –∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–µ–π.

–í –Ω–∞—à–µ–º –∫–∞—Ç–∞–ª–æ–≥–µ –≤—ã –Ω–∞–π–¥–µ—Ç–µ —Ç–æ—Ä–º–æ–∑–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã, —Ñ–∏–ª—å—Ç—Ä—ã (–º–∞—Å–ª—è–Ω—ã–µ, –≤–æ–∑–¥—É—à–Ω—ã–µ, —Å–∞–ª–æ–Ω–Ω—ã–µ), —Å–≤–µ—á–∏ –∑–∞–∂–∏–≥–∞–Ω–∏—è, —Ä–∞—Å—Ö–æ–¥–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –∞–≤—Ç–æ—Ö–∏–º–∏—é, —ç–ª–µ–∫—Ç—Ä–∏–∫—É, –∞–≤—Ç–æ–º–∞—Å–ª–∞, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∞ —Ç–∞–∫–∂–µ –¥—Ä—É–≥–∏–µ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏–µ, –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. 

–ú—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –±—ã—Å—Ç—Ä—É—é –¥–æ—Å—Ç–∞–≤–∫—É, –≤—ã–≥–æ–¥–Ω—ã–µ —Ü–µ–Ω—ã –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –¥–ª—è –ª—é–±–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ ‚Äî –∞–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—è, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –∏–ª–∏ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–∞. 

–í—ã–±–∏—Ä–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ –ª—É—á—à–µ–µ ‚Äî –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç –≤–µ–¥—É—â–∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π."""}$$ AS text
        ),
        PartDetails AS (
            SELECT
                cr.artikul_norm,
                cr.brand_norm,
                STRING_AGG(DISTINCT regexp_replace(regexp_replace(o.oe_number, '''', ''), '[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\\-\\s]', '', 'g'), ', ') AS oe_list,
                ANY_VALUE(o.name) AS representative_name,
                ANY_VALUE(o.applicability) AS representative_applicability,
                ANY_VALUE(o.category) AS representative_category
            FROM cross_references cr
            JOIN oe_data o ON cr.oe_number_norm = o.oe_number_norm
            GROUP BY cr.artikul_norm, cr.brand_norm
        ),
        AllAnalogs AS (
            -- –ê–Ω–∞–ª–æ–≥–∏
            SELECT
                cr1.artikul_norm,
                cr1.brand_norm,
                STRING_AGG(DISTINCT regexp_replace(regexp_replace(p2.artikul, '''', ''), '[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\\-\\s]', '', 'g'), ', ') as analog_list
            FROM cross_references cr1
            JOIN cross_references cr2 ON cr1.oe_number_norm = cr2.oe_number_norm
            JOIN parts_data p2 ON cr2.artikul_norm = p2.artikul_norm AND cr2.brand_norm = p2.brand_norm
            WHERE (cr1.artikul_norm != p2.artikul_norm OR cr1.brand_norm != p2.brand_norm)
            GROUP BY cr1.artikul_norm, cr1.brand_norm
        ),
        InitialOENumbers AS (
            SELECT DISTINCT
                p.artikul_norm,
                p.brand_norm,
                cr.oe_number_norm
            FROM parts_data p
            LEFT JOIN cross_references cr ON p.artikul_norm = cr.artikul_norm AND p.brand_norm = cr.brand_norm
            WHERE cr.oe_number_norm IS NOT NULL
        ),
        Level1Analogs AS (
            SELECT DISTINCT
                i.artikul_norm AS source_artikul_norm,
                i.brand_norm AS source_brand_norm,
                cr2.artikul_norm AS related_artikul_norm,
                cr2.brand_norm AS related_brand_norm
            FROM InitialOENumbers i
            JOIN cross_references cr2 ON i.oe_number_norm = cr2.oe_number_norm
            WHERE NOT (i.artikul_norm = cr2.artikul_norm AND i.brand_norm = cr2.brand_norm)
        ),
        Level1OENumbers AS (
            SELECT DISTINCT
                l1.source_artikul_norm,
                l1.source_brand_norm,
                cr3.oe_number_norm
            FROM Level1Analogs l1
            JOIN cross_references cr3 ON l1.related_artikul_norm = cr3.artikul_norm 
                                        AND l1.related_brand_norm = cr3.brand_norm
            WHERE NOT EXISTS (
                SELECT 1 FROM InitialOENumbers i 
                WHERE i.artikul_norm = l1.source_artikul_norm 
                AND i.brand_norm = l1.source_brand_norm 
                AND i.oe_number_norm = cr3.oe_number_norm
            )
        ),
        Level2Analogs AS (
            SELECT DISTINCT
                loe.source_artikul_norm,
                loe.source_brand_norm,
                cr4.artikul_norm AS related_artikul_norm,
                cr4.brand_norm AS related_brand_norm
            FROM Level1OENumbers loe
            JOIN cross_references cr4 ON loe.oe_number_norm = cr4.oe_number_norm
            WHERE NOT (loe.source_artikul_norm = cr4.artikul_norm AND loe.source_brand_norm = cr4.brand_norm)
        ),
        AllRelatedParts AS (
            SELECT DISTINCT source_artikul_norm, source_brand_norm, related_artikul_norm, related_brand_norm
            FROM Level1Analogs
            UNION
            SELECT DISTINCT source_artikul_norm, source_brand_norm, related_artikul_norm, related_brand_norm
            FROM Level2Analogs
        ),
        AggregatedAnalogData AS (
            SELECT
                arp.source_artikul_norm AS artikul_norm,
                arp.source_brand_norm AS brand_norm,
                MAX(CASE WHEN p2.length IS NOT NULL THEN p2.length ELSE NULL END) AS length,
                MAX(CASE WHEN p2.width IS NOT NULL THEN p2.width ELSE NULL END) AS width,
                MAX(CASE WHEN p2.height IS NOT NULL THEN p2.height ELSE NULL END) AS height,
                MAX(CASE WHEN p2.weight IS NOT NULL THEN p2.weight ELSE NULL END) AS weight,
                ANY_VALUE(CASE WHEN p2.dimensions_str IS NOT NULL 
                               AND p2.dimensions_str != '' 
                               AND UPPER(TRIM(p2.dimensions_str)) != 'XX' 
                          THEN p2.dimensions_str ELSE NULL END) AS dimensions_str,
                ANY_VALUE(CASE WHEN pd2.representative_name IS NOT NULL AND pd2.representative_name != '' THEN pd2.representative_name ELSE NULL END) AS representative_name,
                ANY_VALUE(CASE WHEN pd2.representative_applicability IS NOT NULL AND pd2.representative_applicability != '' THEN pd2.representative_applicability ELSE NULL END) AS representative_applicability,
                ANY_VALUE(CASE WHEN pd2.representative_category IS NOT NULL AND pd2.representative_category != '' THEN pd2.representative_category ELSE NULL END) AS representative_category
            FROM AllRelatedParts arp
            JOIN parts_data p2 ON arp.related_artikul_norm = p2.artikul_norm AND arp.related_brand_norm = p2.brand_norm
            LEFT JOIN PartDetails pd2 ON p2.artikul_norm = pd2.artikul_norm AND p2.brand_norm = pd2.brand_norm
            GROUP BY arp.source_artikul_norm, arp.source_brand_norm
        ),
        RankedData AS (
            SELECT
                p.artikul,
                p.brand,
                p.description,
                p.multiplicity,
                p.length,
                p.width,
                p.height,
                p.weight,
                p.dimensions_str,
                p.image_url,
                pd.representative_name,
                pd.representative_applicability,
                pd.representative_category,
                pd.oe_list,
                aa.analog_list,
                p_analog.length AS analog_length,
                p_analog.width AS analog_width,
                p_analog.height AS analog_height,
                p_analog.weight AS analog_weight,
                p_analog.dimensions_str AS analog_dimensions_str,
                p_analog.representative_name AS analog_representative_name,
                p_analog.representative_applicability AS analog_representative_applicability,
                p_analog.representative_category AS analog_representative_category,
                ROW_NUMBER() OVER(PARTITION BY p.artikul_norm, p.brand_norm ORDER BY pd.representative_name DESC NULLS LAST, pd.oe_list DESC NULLS LAST) as rn,
                -- placeholder –¥–ª—è final_price
                0 AS final_price
            FROM parts_data p
            LEFT JOIN PartDetails pd ON p.artikul_norm = pd.artikul_norm AND p.brand_norm = pd.brand_norm
            LEFT JOIN AllAnalogs aa ON p.artikul_norm = aa.artikul_norm AND p.brand_norm = aa.brand_norm
            LEFT JOIN AggregatedAnalogData p_analog ON p.artikul_norm = p_analog.artikul_norm AND p.brand_norm = p_analog.brand_norm
        )
        """

        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —Ä–∞—Å—á–µ—Ç–æ–º —Ü–µ–Ω—ã
        query = f"""
        {ctes}
        SELECT
            {', '.join(selected_exprs)}
        FROM RankedData r
        LEFT JOIN recommended_prices rp ON r.artikul_norm = rp.artikul_norm AND r.brand_norm = rp.brand_norm
        LEFT JOIN parts_data p ON r.artikul_norm = p.artikul_norm AND r.brand_norm = p.brand_norm
        LEFT JOIN (
            SELECT
                p2.artikul_norm,
                p2.brand_norm,
                -- —Ä–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏
                COALESCE(rp.recommended_price, 0) * (1 + {self.overall_markup / 100}) * (1 + self.get_brand_markup('p2.brand')/100) AS final_price
            FROM parts_data p2
            LEFT JOIN recommended_prices rp ON p2.artikul_norm = rp.artikul_norm AND p2.brand_norm = rp.brand_norm
        ) p2 ON r.artikul_norm = p2.artikul_norm AND r.brand_norm = p2.brand_norm
        WHERE r.rn = 1
        {exclude_sql}
        ORDER BY r.brand, r.artikul
        """
        return query, params

    def export_to_csv_optimized(self, output_path: str, selected_columns: List[str] | None = None, exclude_terms: str = "") -> bool:
        total_records = self.conn.execute("SELECT COUNT(*) FROM (SELECT DISTINCT artikul_norm, brand_norm FROM parts_data) AS t").fetchone()[0]
        if total_records == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False
        st.info(f"üì§ –≠–∫—Å–ø–æ—Ä—Ç {total_records:,} –∑–∞–ø–∏—Å–µ–π –≤ CSV...")
        try:
            query, params = self._build_full_query(selected_columns, exclude_terms)
            df = self.conn.execute(query, params).pl()

            # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–∞
            for col_name in ["–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞", "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å"]:
                if col_name in df.columns:
                    df = df.with_columns(
                        pl.when(pl.col(col_name).is_not_null())
                        .then(pl.col(col_name).cast(pl.Utf8))
                        .otherwise(pl.lit(""))
                        .alias(col_name)
                    )

            buf = io.StringIO()
            df.write_csv(buf, separator=';')
            csv_text = buf.getvalue()

            with open(output_path, 'wb') as f:
                f.write(b'\xef\xbb\xbf')
                f.write(csv_text.encode('utf-8'))

            file_size = os.path.getsize(output_path) / (1024 * 1024)
            st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ CSV: {output_path} ({file_size:.1f} –ú–ë)")
            return True
        except Exception as e:
            print(e)
            st.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ CSV: {e}")
            return False

    def export_to_excel(self, output_path: Path, selected_columns: List[str], exclude_terms: str):
        total_records = self.conn.execute("SELECT COUNT(DISTINCT (artikul_norm, brand_norm)) FROM parts_data").fetchone()[0]
        if total_records == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return False
        num_files = (total_records + EXCEL_ROW_LIMIT - 1) // EXCEL_ROW_LIMIT
        for i in range(num_files):
            query, params = self._build_full_query(selected_columns, exclude_terms)
            df = self.conn.execute(f"{query} LIMIT {EXCEL_ROW_LIMIT} OFFSET {i*EXCEL_ROW_LIMIT}", params).pl()
            # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–∞
            for col_name in ["–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞", "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å"]:
                if col_name in df.columns:
                    df = df.with_columns(
                        pl.when(pl.col(col_name).is_not_null())
                        .then(pl.col(col_name).cast(pl.Utf8))
                        .otherwise(pl.lit(""))
                        .alias(col_name)
                    )
            file_part_path = output_path.with_name(f"{output_path.stem}_part_{i+1}.xlsx")
            df.write_excel(str(file_part_path))
        return True

    def export_to_parquet(self, output_path: str, selected_columns: List[str], exclude_terms: str):
        query, params = self._build_full_query(selected_columns, exclude_terms)
        df = self.conn.execute(query, params).pl()
        df.write_parquet(output_path)
        return True

    def _build_full_query(self, selected_columns: List[str], exclude_terms: str):
        # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –≤—ã–∑–æ–≤ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ SQL
        query, params = self.build_export_query(selected_columns, exclude_terms)
        return query, params

    def show_export_interface(self):
        st.header("üì§ –£–º–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        total_records = self.conn.execute("SELECT count(DISTINCT (artikul_norm, brand_norm)) FROM parts_data").fetchone()[0]
        st.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {total_records:,}")
        if total_records == 0:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return

        exclude_terms = st.text_input("–ò—Å–∫–ª—é—á–∏—Ç—å –ø–æ–∑–∏—Ü–∏–∏ (—á–µ—Ä–µ–∑ |):", value="")
        selected_columns = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã", options=[
            "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", "–ë—Ä–µ–Ω–¥", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", "–û–ø–∏—Å–∞–Ω–∏–µ",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", "–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞",
            "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "OE –Ω–æ–º–µ—Ä", "–∞–Ω–∞–ª–æ–≥–∏", "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–¶–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏"
        ], default=[
            "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", "–ë—Ä–µ–Ω–¥", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", "–û–ø–∏—Å–∞–Ω–∏–µ",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", "–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞",
            "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "OE –Ω–æ–º–µ—Ä", "–∞–Ω–∞–ª–æ–≥–∏", "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–¶–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞—Ü–µ–Ω–∫–∏"
        ])

        export_format = st.radio("–§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞:", ["CSV", "Excel (.xlsx)", "Parquet"], index=0)

        if st.button("üöÄ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å", type="primary"):
            output_path = self.data_dir / "auto_parts_export"
            if export_format == "CSV":
                out_file = str(output_path.with_suffix('.csv'))
                with st.spinner("–≠–∫—Å–ø–æ—Ä—Ç –≤ CSV..."):
                    self.export_to_csv_optimized(out_file, selected_columns, exclude_terms)
                with open(out_file, "rb") as f:
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å CSV", f, "auto_parts_export.csv", "text/csv")
            elif export_format == "Excel (.xlsx)":
                out_file = output_path.with_suffix('.xlsx')
                with st.spinner("–≠–∫—Å–ø–æ—Ä—Ç –≤ Excel..."):
                    self.export_to_excel(out_file, selected_columns, exclude_terms)
                with open(out_file, "rb") as f:
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å Excel", f, "auto_parts_export.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            elif export_format == "Parquet":
                out_file = str(output_path.with_suffix('.parquet'))
                with st.spinner("–≠–∫—Å–ø–æ—Ä—Ç –≤ Parquet..."):
                    self.export_to_parquet(out_file, selected_columns, exclude_terms)
                with open(out_file, "rb") as f:
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å Parquet", f, "auto_parts_export.parquet", "application/octet-stream")

    # –ú–µ—Ç–æ–¥—ã –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
    def load_files(self, files_dict: Dict[str, str]):
        for ftype, path in files_dict.items():
            if ftype == 'recommended_prices':
                self.load_recommended_prices(path)
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

    # –ú–µ—Ç–æ–¥ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞—Ü–µ–Ω–∫–∏
    def configure_markups(self):
        self.overall_markup = st.number_input("–û–±—â–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ (%)", value=0.0, step=1.0)
        brand_markups_input = st.text_area("–ù–∞—Ü–µ–Ω–∫–∏ –ø–æ –±—Ä–µ–Ω–¥–∞–º (—Ñ–æ—Ä–º–∞—Ç: –±—Ä–µ–Ω–¥:–ø—Ä–æ—Ü–µ–Ω—Ç, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)", value="")
        self.brand_markups = {}
        if brand_markups_input:
            pairs = [pair.strip() for pair in brand_markups_input.split(',') if pair.strip()]
            for pair in pairs:
                if ':' in pair:
                    brand, percent = pair.split(':', 1)
                    self.brand_markups[brand.strip().lower()] = float(percent.strip())

    def get_brand_markup(self, brand_norm: str) -> float:
        return self.brand_markups.get(brand_norm.lower(), self.overall_markup)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫
    def run(self):
        # –í UI –¥–æ–±–∞–≤—å—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞ —Ü–µ–Ω
        st.sidebar.header("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        prices_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏", type=['xlsx', 'xls'])
        if prices_file:
            save_path = self.data_dir / f"recommended_prices_{int(time.time())}_{prices_file.name}"
            with open(save_path, "wb") as f:
                f.write(prices_file.getvalue())
            self.load_recommended_prices(str(save_path))
            st.sidebar.success("–¶–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞—Ü–µ–Ω–æ–∫
        self.configure_markups()

        # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
        self.show_export_interface()


# –í –æ—Å–Ω–æ–≤–Ω–æ–º –∑–∞–ø—É—Å–∫–µ
def main():
    catalog = HighVolumeAutoPartsCatalog()
    catalog.run()

if __name__ == "__main__":
    main()
