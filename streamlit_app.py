import streamlit as st
import duckdb
import polars as pl
import io
import time
import json
import os
from pathlib import Path

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DATA_DIR = Path("./auto_parts_data")
DATA_DIR.mkdir(exist_ok=True)
DB_PATH = DATA_DIR / "catalog.duckdb"

class AutoPartsCatalog:
    def __init__(self):
        self.conn = duckdb.connect(str(DB_PATH))
        self._setup_database()
        self._create_indexes()

    def _setup_database(self):
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS oe_data (
                oe_number_norm VARCHAR PRIMARY KEY,
                oe_number VARCHAR,
                name VARCHAR,
                applicability VARCHAR,
                category VARCHAR
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS parts_data (
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                artikul VARCHAR,
                brand VARCHAR,
                multiplicity INTEGER,
                barcode VARCHAR,
                length DOUBLE,
                width DOUBLE,
                height DOUBLE,
                weight DOUBLE,
                image_url VARCHAR,
                dimensions_str VARCHAR,
                description VARCHAR,
                price_with_markup DOUBLE,
                category VARCHAR,
                PRIMARY KEY (artikul_norm, brand_norm)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS cross_references (
                oe_number_norm VARCHAR,
                artikul_norm VARCHAR,
                brand_norm VARCHAR,
                PRIMARY KEY (oe_number_norm, artikul_norm, brand_norm)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS recommended_prices (
                artikul_norm VARCHAR PRIMARY KEY,
                price DOUBLE
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS price_list (
                artikul VARCHAR,
                brand VARCHAR,
                quantity INTEGER,
                price DOUBLE,
                PRIMARY KEY (artikul, brand)
            )
        """)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS markup_settings (
                id INTEGER PRIMARY KEY,
                total_markup DOUBLE,
                brand_markup JSON
            )
        """)
        if not self.conn.execute("SELECT 1 FROM markup_settings").fetchone():
            self.conn.execute("INSERT INTO markup_settings (id, total_markup, brand_markup) VALUES (1, 0, '{}')")
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS categories (
                name VARCHAR PRIMARY KEY,
                description VARCHAR
            )
        """)

    def _create_indexes(self):
        # –ò–Ω–¥–µ–∫—Å—ã
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_oe ON oe_data(oe_number_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_parts ON parts_data(artikul_norm, brand_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_cross ON cross_references(oe_number_norm)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_cross_art ON cross_references(artikul_norm, brand_norm)")

    # --- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ ---
    def get_categories(self):
        return self.conn.execute("SELECT name, description FROM categories").fetchdf()

    def add_category(self, name, description=''):
        try:
            self.conn.execute("INSERT INTO categories (name, description) VALUES (?, ?)", [name, description])
        except Exception:
            pass

    def delete_category(self, name):
        self.conn.execute("DELETE FROM categories WHERE name=?", [name])

    def update_category_name(self, old_name, new_name):
        self.conn.execute("UPDATE categories SET name=? WHERE name=?", [new_name, old_name])

    def load_categories(self, file_bytes):
        try:
            df = pl.read_excel(io.BytesIO(file_bytes))
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
            return
        if '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' not in df.columns or '–∫–∞—Ç–µ–≥–æ—Ä–∏—è' not in df.columns:
            st.error("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' –∏ '–∫–∞—Ç–µ–≥–æ—Ä–∏—è'")
            return
        df = df.select([pl.col('–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ'), pl.col('–∫–∞—Ç–µ–≥–æ—Ä–∏—è')])
        self.conn.execute("DELETE FROM categories")
        for row in df.iter_rows():
            self.add_category(row[0], row[1])

    def show_categories(self):
        df = self.get_categories()
        st.subheader("–¢–µ–∫—É—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
        edited_df = st.experimental_data_editor(df, use_container_width=True)
        if st.button("–û–±–Ω–æ–≤–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"):
            original_names = df['name'].tolist()
            updated_names = edited_df['name'].tolist()
            for old_name, new_name in zip(original_names, edited_df['name']):
                if old_name != new_name:
                    self.update_category_name(old_name, new_name)
            for name in original_names:
                if name not in edited_df['name'].tolist():
                    self.delete_category(name)
            st.success("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ ---
    def read_and_prepare_file(self, filepath, key):
        try:
            df = pl.read_excel(filepath)
            if key == 'oe':
                df = df.rename({"‚Ññ OE": "oe_number", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ": "name", "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å": "applicability", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": "category"})
                df['oe_number_norm'] = df['oe_number'].str.strip().str.upper()
            elif key == 'cross':
                df = df.rename({"OE": "oe_number", "–ê—Ä—Ç–∏–∫—É–ª": "artikul", "–ë—Ä–µ–Ω–¥": "brand"})
                df['oe_number_norm'] = df['oe_number'].str.strip().str.upper()
                df['artikul_norm'] = df['artikul'].str.strip().str.upper()
            elif key == 'barcode':
                df = df.rename({"–ê—Ä—Ç–∏–∫—É–ª": "artikul", "–ë—Ä–µ–Ω–¥": "brand", "–®—Ç—Ä–∏—Ö–∫–æ–¥": "barcode"})
            elif key == 'dimensions':
                df = df.rename({"–ê—Ä—Ç–∏–∫—É–ª": "artikul", "–ë—Ä–µ–Ω–¥": "brand", "–î–ª–∏–Ω–∞": "length", "–®–∏—Ä–∏–Ω–∞": "width", "–í—ã—Å–æ—Ç–∞": "height", "–í–µ—Å": "weight"})
            elif key == 'images':
                df = df.rename({"–ê—Ä—Ç–∏–∫—É–ª": "artikul", "–ë—Ä–µ–Ω–¥": "brand", "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ": "image_url"})
            elif key == 'categories':
                # —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
                pass
            return df
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filepath}: {e}")
            return None

    def process_and_load(self, dataframes):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        if 'oe' in dataframes:
            df_oe = dataframes['oe']
            for row in df_oe.iter_rows():
                self.conn.execute("""
                    INSERT OR REPLACE INTO oe_data (oe_number_norm, oe_number, name, applicability, category)
                    VALUES (?, ?, ?, ?, ?)
                """, [row['oe_number_norm'], row['oe_number'], row['name'], row.get('applicability', ''), row.get('category', '')])
        if 'cross' in dataframes:
            df_cross = dataframes['cross']
            for row in df_cross.iter_rows():
                self.conn.execute("""
                    INSERT OR REPLACE INTO cross_references (oe_number_norm, artikul_norm, brand_norm)
                    VALUES (?, ?, ?)
                """, [row['oe_number'].strip().upper(), row['artikul'].strip().upper(), row['brand'].strip().upper()])
        if 'barcode' in dataframes:
            pass
        if 'dimensions' in dataframes:
            df_dim = dataframes['dimensions']
            for row in df_dim.iter_rows():
                self.conn.execute("""
                    UPDATE OR INSERT INTO parts_data (artikul_norm, brand_norm, length, width, height, weight)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, [row['artikul'].strip().upper(), row['brand'].strip().upper(), row['length'], row['width'], row['height'], row['weight']])

    def load_recommended_prices(self, file_bytes):
        try:
            df = pl.read_excel(io.BytesIO(file_bytes))
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return
        if '–ê—Ä—Ç–∏–∫—É–ª' not in df.columns or '–¶–µ–Ω–∞' not in df.columns:
            st.error("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å '–ê—Ä—Ç–∏–∫—É–ª' –∏ '–¶–µ–Ω–∞'")
            return
        for row in df.iter_rows():
            artikul = row['–ê—Ä—Ç–∏–∫—É–ª'].strip().upper()
            price = row['–¶–µ–Ω–∞']
            self.conn.execute("""
                INSERT OR REPLACE INTO recommended_prices (artikul_norm, price)
                VALUES (?, ?)
            """, [artikul, price])
        st.success("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ü–µ–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

    def load_price_list(self, file_bytes):
        try:
            df = pl.read_excel(io.BytesIO(file_bytes))
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞: {e}")
            return
        if not {'–ê—Ä—Ç–∏–∫—É–ª', '–ë—Ä–µ–Ω–¥', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–¶–µ–Ω–∞'}.issubset(df.columns):
            st.error("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å '–ê—Ä—Ç–∏–∫—É–ª', '–ë—Ä–µ–Ω–¥', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–¶–µ–Ω–∞'")
            return
        for row in df.iter_rows():
            artikul = row['–ê—Ä—Ç–∏–∫—É–ª'].strip().upper()
            brand = row['–ë—Ä–µ–Ω–¥'].strip()
            quantity = row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
            price = row['–¶–µ–Ω–∞']
            self.conn.execute("""
                INSERT OR REPLACE INTO price_list (artikul, brand, quantity, price)
                VALUES (?, ?, ?, ?)
            """, [artikul, brand, quantity, price])
        st.success("–ü—Ä–∞–π—Å-–ª–∏—Å—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")

    # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–æ–∫ ---
    def get_markups(self):
        row = self.conn.execute("SELECT total_markup, brand_markup FROM markup_settings WHERE id=1").fetchone()
        if row:
            total_markup, brand_markup_json = row
            try:
                brand_markup = json.loads(brand_markup_json) if brand_markup_json else {}
            except:
                brand_markup = {}
            return total_markup, brand_markup
        return 0, {}

    def set_markups(self, total_markup, brand_markup):
        self.conn.execute("""
            UPDATE markup_settings SET total_markup=?, brand_markup=?
            WHERE id=1
        """, [total_markup, json.dumps(brand_markup)])
        st.success("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")

    def apply_markup(self, price, total_markup, brand_markup_dict, brand):
        markup = total_markup
        if brand and brand in brand_markup_dict:
            markup += brand_markup_dict[brand]
        return round(price * (1 + markup / 100), 2)

    # --- –≠–∫—Å–ø–æ—Ä—Ç ---
    def show_export_interface(self):
        st.subheader("üì§ –£–º–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
        total_records = self.conn.execute("SELECT count(DISTINCT (artikul_norm, brand_norm)) FROM parts_data").fetchone()[0]
        st.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (—Å—Ç—Ä–æ–∫): {total_records:,}")
        if total_records == 0:
            st.warning("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ—Ç —Å–≤—è–∑–µ–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
            return

        available_columns = [
            "–ê—Ä—Ç–∏–∫—É–ª –±—Ä–µ–Ω–¥–∞", "–ë—Ä–µ–Ω–¥", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å", "–û–ø–∏—Å–∞–Ω–∏–µ",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞", "–ö—Ä–∞—Ç–Ω–æ—Å—Ç—å", "–î–ª–∏–Ω–Ω–∞", "–®–∏—Ä–∏–Ω–∞", "–í—ã—Å–æ—Ç–∞",
            "–í–µ—Å", "–î–ª–∏–Ω–Ω–∞/–®–∏—Ä–∏–Ω–∞/–í—ã—Å–æ—Ç–∞", "OE –Ω–æ–º–µ—Ä", "–∞–Ω–∞–ª–æ–≥–∏", "–°—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
        ]
        selected_columns = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–ø—É—Å—Ç–æ = –≤—Å–µ)", options=available_columns, default=available_columns)
        exclude_input = st.text_input("–ò—Å–∫–ª—é—á–∏—Ç—å –ø–æ–∑–∏—Ü–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é (—á–µ—Ä–µ–∑ |)", "")

        categories = self.get_categories()['name'].tolist()
        categories.insert(0, '–í—Å–µ')
        category_filter = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º", categories, default=['–í—Å–µ'])
        if '–í—Å–µ' in category_filter:
            category_filter = None
        elif not category_filter:
            category_filter = None
        else:
            category_filter = category_filter

        total_markup_value = st.number_input("–û–±—â–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ (%)", value=0.0, step=0.1)
        brand_markup_df = self.conn.execute("SELECT brand, COUNT(*) as cnt FROM parts_data GROUP BY brand").fetchdf()
        brand_markup_dict = {}
        st.write("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–æ–∫ –ø–æ –±—Ä–µ–Ω–¥–∞–º:")
        for index, row in brand_markup_df.iterrows():
            brand = row['brand']
            default_markup = 0
            markup_value = st.number_input(f"{brand}", value=default_markup, step=0.1, key=f"markup_{brand}")
            brand_markup_dict[brand] = markup_value

        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–∫–∏"):
            self.set_markups(total_markup_value, brand_markup_dict)

        if st.button("–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ"):
            df = self.export_data(
                columns=selected_columns,
                exclude_terms=exclude_input,
                category_filter=None if '–í—Å–µ' in category_filter else category_filter
            )
            if df is not None:
                total_markup, brand_markup = self.get_markups()
                if 'price_with_markup' in df.columns:
                    df = df.with_columns(
                        pl.col('price_with_markup').apply(
                            lambda p, br=pl.col('brand'): self.apply_markup(p, total_markup, brand_markup, br[0])
                        ).alias('price_with_markup')
                    )
                buffer = io.BytesIO()
                df.write_excel(buffer)
                buffer.seek(0)
                filename = f"export_{int(time.time())}.xlsx"
                st.download_button("–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª", data=buffer, file_name=filename, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    def export_data(self, columns=None, exclude_terms='', category_filter=None):
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ SQL-–∑–∞–ø—Ä–æ—Å
        all_columns = {
            'artikul': 'p.artikul',
            'brand': 'p.brand',
            'category': 'p.category',
            'length': 'p.length',
            'width': 'p.width',
            'height': 'p.height',
            'weight': 'p.weight',
            'image_url': 'p.image_url',
            'description': 'p.description',
            'oe_list': 'pd.oe_list',
            'price_with_markup': 'p.price_with_markup'
        }

        select_cols = [all_columns.get(c, c) for c in columns] if columns else list(all_columns.values())

        # –í–µ—Å—å SQL –∏–∑ –≤–∞—à–µ–≥–æ –ø–µ—Ä–≤–æ–≥–æ –∫–æ–¥–∞
        standard_description = """–°–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: –Ω–æ–≤—ã–π (–≤ —É–ø–∞–∫–æ–≤–∫–µ).
–í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–∏ –∏ –∞–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã ‚Äî –Ω–∞–¥–µ–∂–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –≤–∞—à–µ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è. 
–û–±–µ—Å–ø–µ—á—å—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, –¥–æ–ª–≥–æ–≤–µ—á–Ω–æ—Å—Ç—å –∏ –≤—ã—Å–æ–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∞—à–µ–≥–æ –∞–≤—Ç–æ —Å –ø–æ–º–æ—â—å—é –Ω–∞—à–µ–≥–æ —à–∏—Ä–æ–∫–æ–≥–æ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã—Ö –∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–µ–π.

–í –Ω–∞—à–µ–º –∫–∞—Ç–∞–ª–æ–≥–µ –≤—ã –Ω–∞–π–¥–µ—Ç–µ —Ç–æ—Ä–º–æ–∑–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã, —Ñ–∏–ª—å—Ç—Ä—ã (–º–∞—Å–ª—è–Ω—ã–µ, –≤–æ–∑–¥—É—à–Ω—ã–µ, —Å–∞–ª–æ–Ω–Ω—ã–µ), —Å–≤–µ—á–∏ –∑–∞–∂–∏–≥–∞–Ω–∏—è, —Ä–∞—Å—Ö–æ–¥–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –∞–≤—Ç–æ—Ö–∏–º–∏—é, —ç–ª–µ–∫—Ç—Ä–∏–∫—É, –∞–≤—Ç–æ–º–∞—Å–ª–∞, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∞ —Ç–∞–∫–∂–µ –¥—Ä—É–≥–∏–µ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏–µ, –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. 

–ú—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –±—ã—Å—Ç—Ä—É—é –¥–æ—Å—Ç–∞–≤–∫—É, –≤—ã–≥–æ–¥–Ω—ã–µ —Ü–µ–Ω—ã –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –¥–ª—è –ª—é–±–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ ‚Äî –∞–≤—Ç–æ–ª—é–±–∏—Ç–µ–ª—è, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –∏–ª–∏ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–∞. 

–í—ã–±–∏—Ä–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ –ª—É—á—à–µ–µ ‚Äî –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç –≤–µ–¥—É—â–∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π."""
        sql_full = f"""
        WITH DescriptionTemplate AS (
            SELECT CHR(10) || CHR(10) || $${standard_description}$$ AS text
        ),
        PartDetails AS (
            SELECT
                cr.artikul_norm,
                cr.brand_norm,
                STRING_AGG(DISTINCT regexp_replace(regexp_replace(o.oe_number, '''', ''), '[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\\-\\s]', '', 'g'), ', ') AS oe_list,
                ANY_VALUE(o.name) AS representative_name,
                ANY_VALUE(o.applicability) AS representative_applicability,
                ANY_VALUE(o.category) AS representative_category
            FROM cross_references cr
            JOIN oe_data o ON cr.oe_number_norm = o.oe_number_norm
            GROUP BY cr.artikul_norm, cr.brand_norm
        ),
        AllAnalogs AS (
            SELECT
                cr1.artikul_norm,
                cr1.brand_norm,
                STRING_AGG(DISTINCT regexp_replace(regexp_replace(p2.artikul, '''', ''), '[^0-9A-Za-z–ê-–Ø–∞-—è–Å—ë`\\-\\s]', '', 'g'), ', ') as analog_list
            FROM cross_references cr1
            JOIN cross_references cr2 ON cr1.oe_number_norm = cr2.oe_number_norm
            JOIN parts_data p2 ON cr2.artikul_norm = p2.artikul_norm AND cr2.brand_norm = p2.brand_norm
            WHERE (cr1.artikul_norm != p2.artikul_norm OR cr1.brand_norm != p2.brand_norm)
            GROUP BY cr1.artikul_norm, cr1.brand_norm
        ),
        InitialOENumbers AS (
            SELECT DISTINCT
                p.artikul_norm,
                p.brand_norm,
                cr.oe_number_norm
            FROM parts_data p
            LEFT JOIN cross_references cr ON p.artikul_norm = cr.artikul_norm AND p.brand_norm = cr.brand_norm
            WHERE cr.oe_number_norm IS NOT NULL
        ),
        Level1Analogs AS (
            SELECT DISTINCT
                i.artikul_norm AS source_artikul_norm,
                i.brand_norm AS source_brand_norm,
                cr2.artikul_norm AS related_artikul_norm,
                cr2.brand_norm AS related_brand_norm
            FROM InitialOENumbers i
            JOIN cross_references cr2 ON i.oe_number_norm = cr2.oe_number_norm
            WHERE NOT (i.artikul_norm = cr2.artikul_norm AND i.brand_norm = cr2.brand_norm)
        ),
        Level1OENumbers AS (
            SELECT DISTINCT
                l1.source_artikul_norm,
                l1.source_brand_norm,
                cr3.oe_number_norm
            FROM Level1Analogs l1
            JOIN cross_references cr3 ON l1.related_artikul_norm = cr3.artikul_norm 
                                        AND l1.related_brand_norm = cr3.brand_norm
            WHERE NOT EXISTS (
                SELECT 1 FROM InitialOENumbers i 
                WHERE i.artikul_norm = l1.source_artikul_norm 
                AND i.brand_norm = l1.source_brand_norm 
                AND i.oe_number_norm = cr3.oe_number_norm
            )
        ),
        Level2Analogs AS (
            SELECT DISTINCT
                loe.source_artikul_norm,
                loe.source_brand_norm,
                cr4.artikul_norm AS related_artikul_norm,
                cr4.brand_norm AS related_brand_norm
            FROM Level1OENumbers loe
            JOIN cross_references cr4 ON loe.oe_number_norm = cr4.oe_number_norm
            WHERE NOT (loe.source_artikul_norm = cr4.artikul_norm AND loe.source_brand_norm = cr4.brand_norm)
        ),
        AllRelatedParts AS (
            SELECT DISTINCT source_artikul_norm, source_brand_norm, related_artikul_norm, related_brand_norm
            FROM Level1Analogs
            UNION
            SELECT DISTINCT source_artikul_norm, source_brand_norm, related_artikul_norm, related_brand_norm
            FROM Level2Analogs
        ),
        AggregatedData AS (
            SELECT
                arp.source_artikul_norm AS artikul_norm,
                arp.source_brand_norm AS brand_norm,
                MAX(CASE WHEN p2.length IS NOT NULL THEN p2.length ELSE NULL END) AS length,
                MAX(CASE WHEN p2.width IS NOT NULL THEN p2.width ELSE NULL END) AS width,
                MAX(CASE WHEN p2.height IS NOT NULL THEN p2.height ELSE NULL END) AS height,
                MAX(CASE WHEN p2.weight IS NOT NULL THEN p2.weight ELSE NULL END) AS weight,
                ANY_VALUE(CASE WHEN p2.dimensions_str IS NOT NULL AND p2.dimensions_str != '' AND UPPER(TRIM(p2.dimensions_str)) != 'XX' THEN p2.dimensions_str ELSE NULL END) AS dimensions_str,
                ANY_VALUE(CASE WHEN pd2.representative_name IS NOT NULL AND pd2.representative_name != '' THEN pd2.representative_name ELSE NULL END) AS representative_name,
                ANY_VALUE(CASE WHEN pd2.representative_applicability IS NOT NULL AND pd2.representative_applicability != '' THEN pd2.representative_applicability ELSE NULL END) AS representative_applicability,
                ANY_VALUE(CASE WHEN pd2.representative_category IS NOT NULL AND pd2.representative_category != '' THEN pd2.representative_category ELSE NULL END) AS representative_category
            FROM AllRelatedParts arp
            JOIN parts_data p2 ON arp.related_artikul_norm = p2.artikul_norm AND arp.related_brand_norm = p2.brand_norm
            LEFT JOIN PartDetails pd2 ON p2.artikul_norm = pd2.artikul_norm AND p2.brand_norm = pd2.brand_norm
            GROUP BY arp.source_artikul_norm, arp.source_brand_norm
        ),
        RankedData AS (
            SELECT
                p.artikul,
                p.brand,
                p.description,
                p.multiplicity,
                p.length,
                p.width,
                p.height,
                p.weight,
                p.dimensions_str,
                p.image_url,
                pd.representative_name,
                pd.representative_applicability,
                pd.representative_category,
                pd.oe_list,
                aa.analog_list,
                p_analog.length AS analog_length,
                p_analog.width AS analog_width,
                p_analog.height AS analog_height,
                p_analog.weight AS analog_weight,
                p_analog.dimensions_str AS analog_dimensions_str,
                p_analog.representative_name AS analog_representative_name,
                p_analog.representative_applicability AS analog_representative_applicability,
                p_analog.representative_category AS analog_representative_category,
                ROW_NUMBER() OVER(PARTITION BY p.artikul_norm, p.brand_norm ORDER BY pd.representative_name DESC NULLS LAST, pd.oe_list DESC NULLS LAST) as rn
            FROM parts_data p
            LEFT JOIN PartDetails pd ON p.artikul_norm = pd.artikul_norm AND p.brand_norm = pd.brand_norm
            LEFT JOIN AllAnalogs aa ON p.artikul_norm = aa.artikul_norm AND p.brand_norm = aa.brand_norm
            LEFT JOIN AggregatedData p_analog ON p.artikul_norm = p_analog.artikul_norm AND p.brand_norm = p_analog.brand_norm
        )
        """

        select_clause = ",\n            ".join(select_cols)

        # –ò—Ç–æ–≥–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        query = f"""
        {sql_full}
        SELECT
            {select_clause}
        FROM RankedData r
        CROSS JOIN DescriptionTemplate dt
        WHERE r.rn = 1
        ORDER BY r.brand, r.artikul
        """
        return query

# --- –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ---
def main():
    st.set_page_config(page_title="AutoParts Catalog", layout="wide")
    st.title("üöó AutoParts Catalog ‚Äî –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç")
    catalog = AutoPartsCatalog()

    menu = st.sidebar.radio("–ú–µ–Ω—é", ["–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö", "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", "–ù–∞—Å—Ç—Ä–æ–π–∫–∏", "–≠–∫—Å–ø–æ—Ä—Ç", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ü–µ–Ω", "–ü—Ä–∞–π—Å-–ª–∏—Å—Ç"])

    if menu == "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö":
        st.subheader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        col1, col2 = st.columns(2)
        with col1:
            file_oe = st.file_uploader("–û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (OE)", type=['xlsx', 'xls'])
            file_cross = st.file_uploader("–ö—Ä–æ—Å—Å—ã (OE ‚Üí –ê—Ä—Ç–∏–∫—É–ª)", type=['xlsx', 'xls'])
            file_barcode = st.file_uploader("–®—Ç—Ä–∏—Ö-–∫–æ–¥—ã", type=['xlsx', 'xls'])
        with col2:
            file_dim = st.file_uploader("–í–µ—Å–æ–≥–∞–±–∞—Ä–∏—Ç—ã", type=['xlsx', 'xls'])
            file_img = st.file_uploader("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", type=['xlsx', 'xls'])
            file_category = st.file_uploader("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ, –∫–∞—Ç–µ–≥–æ—Ä–∏—è)", type=['xlsx', 'xls'])

        files_map = {
            'oe': file_oe,
            'cross': file_cross,
            'barcode': file_barcode,
            'dimensions': file_dim,
            'images': file_img,
            'categories': file_category
        }

        if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª—ã"):
            dataframes = {}
            for key, uploaded in files_map.items():
                if uploaded:
                    filename = f"{key}_{int(time.time())}_{uploaded.name}"
                    path = DATA_DIR / filename
                    with open(path, "wb") as f:
                        f.write(uploaded.read())
                    df = catalog.read_and_prepare_file(str(path), key)
                    dataframes[key] = df
            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
            if 'categories' in files_map and files_map['categories']:
                catalog.load_categories(files_map['categories'].read())

            if dataframes:
                catalog.process_and_load(dataframes)
                st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            else:
                st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")

    elif menu == "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏":
        catalog.show_categories()

    elif menu == "–ù–∞—Å—Ç—Ä–æ–π–∫–∏":
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–æ–∫")
        total_markup, brand_markup = catalog.get_markups()
        new_total_markup = st.number_input("–û–±—â–∞—è –Ω–∞—Ü–µ–Ω–∫–∞ (%)", value=total_markup, step=0.1)
        brand_df = catalog.conn.execute("SELECT brand FROM parts_data GROUP BY brand").fetchdf()
        brand_markup_dict = {}
        st.write("–ù–∞—Ü–µ–Ω–∫–∏ –ø–æ –±—Ä–µ–Ω–¥–∞–º:")
        for index, row in brand_df.iterrows():
            brand = row['brand']
            default_markup = 0
            markup_value = st.number_input(f"{brand}", value=default_markup, step=0.1, key=f"markup_{brand}")
            brand_markup_dict[brand] = markup_value
        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞—Ü–µ–Ω–∫–∏"):
            catalog.set_markups(new_total_markup, brand_markup_dict)

    elif menu == "–≠–∫—Å–ø–æ—Ä—Ç":
        catalog.show_export_interface()

    elif menu == "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
        stats = catalog.get_statistics()
        st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        st.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—á–∞—Å—Ç–µ–π: {stats['total_parts']}")
        st.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {stats['total_categories']}")

    elif menu == "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ü–µ–Ω":
        uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ —Ü–µ–Ω–∞–º", type=['xlsx', 'xls'])
        if uploaded:
            catalog.load_recommended_prices(uploaded.read())

    elif menu == "–ü—Ä–∞–π—Å-–ª–∏—Å—Ç":
        uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç", type=['xlsx', 'xls'])
        if uploaded:
            catalog.load_price_list(uploaded.read())

if __name__ == "__main__":
    main()
